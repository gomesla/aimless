{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d7d315-724b-4c2d-9afe-6a85bdb590fc",
   "metadata": {},
   "source": [
    "### Imports, Constants, Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e59cc4-5d59-410e-84fc-3da80097585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.getipython import get_ipython\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import pandas as pd\n",
    "import json \n",
    "\n",
    "DEV_MODE = False\n",
    "RESULT_DIR = './analysis_results'\n",
    "if DEV_MODE:\n",
    "    RESULT_DIR = RESULT_DIR + '_dev'\n",
    "RESULT_FILE_PREFIX = RESULT_DIR +'/module_11_01.'\n",
    "STEP01_DATA_UNDERSTANDING = 'step01.data_understanding.'\n",
    "STEP02_DATA_PREPARATION = 'step02.data_preparation.'\n",
    "STEP03_MODELING = 'step03.modeling.'\n",
    "STEP04_EVALUATION = 'step04.evaluation.'\n",
    "\n",
    "def writeString2File(string2Write, path, print2Screen = True):\n",
    "    if print2Screen:\n",
    "        print(string2Write)\n",
    "    with open(path, \"w\") as text_file:\n",
    "        text_file.write(str(string2Write))\n",
    "\n",
    "def readFile(path):\n",
    "    with open(path) as f: \n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def readJson(path):\n",
    "    data = readFile(path)\n",
    "    return json.loads(data)\n",
    "\n",
    "def addMarkdownImage(name, path, asMarkdown=False):\n",
    "    if asMarkdown:\n",
    "        out = f'![{name}]({path})'\n",
    "    else:\n",
    "        out = f'<a href=\"{path}\" target=\"_blank\"><img src=\"{path}\"/></a>'\n",
    "\n",
    "    return out\n",
    "\n",
    "content = '# Report: What drives the price of a car?\\n\\n'\n",
    "\n",
    "def printDataFrameInfo(name, stage):\n",
    "    out = ''\n",
    "    out += f'### {name}\\n\\n'\n",
    "    out += '<table>'\n",
    "    out += '<tr><th>info()</th><th>describe()</th></tr>'\n",
    "\n",
    "    prefix = RESULT_FILE_PREFIX + stage\n",
    "    rawDfInfo = readFile(prefix + 'data.info.txt')\n",
    "    rawDfDescribe = readFile(prefix + 'data.describe.txt')\n",
    "    imgPath = prefix + 'data.distribution.png'\n",
    "    \n",
    "    rawDfStatsImage = addMarkdownImage(name, imgPath)\n",
    "    out += '<tr>'\n",
    "    out += f'<td><pre>{rawDfInfo}</pre></td>'\n",
    "    out += f'<td><pre>{rawDfDescribe}</pre></td>'\n",
    "    out += '</tr>'\n",
    "    out += '<tr>'\n",
    "    out += f'<td colspan=\"2\">\\n{rawDfStatsImage}\\n</td></tr>'\n",
    "    out += '</tr>'\n",
    "    out += '</table>\\n\\n'\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06e90e-a475-47db-90c6-df66291ba905",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eb7b31-6f80-48ea-8c27-17e11d02d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This will fail for large dataset processing or complex model evaluation\n",
    "# Use the command below to run it in the background \n",
    "##############################\n",
    "# Source: https://www.maksimeren.com/post/screen-and-jupyter-a-way-to-run-long-notebooks-headless/\n",
    "# jupyter nbconvert --to notebook --execute used_car_price_analysis.template.ipynb --output=used_car_price_analysis.out.ipynb --ExecutePreprocessor.timeout=-1\n",
    "content += '**Code:** [Data Analysis Workbook](./used_car_price_analysis.out.ipynb)\\n\\n'\n",
    "content += '**NOTE:** *The processing of the juypter notebook take a long time and often disconnects from the session. In order to run it without monitoring it all the time use the wokraround below from command line.*\\n\\n'\n",
    "content += '```\\n'\n",
    "content += 'jupyter nbconvert --to notebook --execute used_car_price_analysis.template.ipynb --output=used_car_price_analysis.out.ipynb --ExecutePreprocessor.timeout=-1\\n'\n",
    "content += '```\\n'\n",
    "content += '<sub>Source: [screen-and-jupyter-a-way-to-run-long-notebooks-headles](https://www.maksimeren.com/post/screen-and-jupyter-a-way-to-run-long-notebooks-headless/)</sub>\\n\\n'\n",
    "\n",
    "content += 'Jump to the good stuff: [Recommendations](#Recommendations)\\n\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40439c5c-4e0c-4ce5-9107-7bd316acd1bc",
   "metadata": {},
   "source": [
    "### Business Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d38490-a83a-4bdb-93b3-20e9b1805893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#content += '\\n\\n'\n",
    "content += '## Business Understanding\\n\\n'\n",
    "\n",
    "content += 'We are provided with a dataset of used car prices and features about that particular vehicle. Our final goal will be to identify which \\'features\\' AND what values of those features most contribute to the final price both positively and negatively.\\n\\n'\n",
    "content += 'Because the data has high dimensionality we will need to make use of transformers to get the data ready for use in regularization. Once data is cleaned and prepared we will then try out multiple linear regression models to find the best one. Once done we will use the coefficients to identify how features contribute to price.\\n\\n'\n",
    "content += 'Once we have found these imortant features we will write up actionable guidance for used car business\\n\\n'\n",
    "content += '**Steps involved:**\\n\\n'\n",
    "content += '  - Examine the raw data and identify characterisitics of the data e.g. missing values, unique counts, invalid data...\\n'\n",
    "content += '  - Preprocess the data to get it ready for modelling by:\\n'\n",
    "content += '    - Identifying which features can be ignored and drop those columns/features\\n'\n",
    "content += '    - Identify non-ignorable missing features and either:\\n'\n",
    "content += '      - Impute missing values per row\\n'\n",
    "content += '      - Drop those rows\\n'\n",
    "content += '  - Decide what data transforms/normalization are required for numeric and categorical fields based on above decisions\\n'\n",
    "content += '  - Use regularization techniques with multiple (L1, L2,...) linear regression models using and find one with the best peformance for predicting prices\\n'\n",
    "content += '  - Repeat steps above if necessary to arrive at final \\'best\\' model which we will measure by using the one with the lowest Mean Square Error (MSE)\\n'\n",
    "content += '  - Analyse the most important features \\'selected\\' by the model based on the coefficients determined by the previous steps\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0801b9-9a62-4dcb-9fd8-edbe51fd4515",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32372cf-a6e9-4999-b09d-58471f60ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Understanding\n",
    "content += '## Data Understanding\\n\\n'\n",
    "content += printDataFrameInfo('Raw Data Statistics', STEP01_DATA_UNDERSTANDING)\n",
    "\n",
    "fieldNotes = {\n",
    "    'id': {\n",
    "        'notes': [\n",
    "            'Not useful for predictions.'\n",
    "        ]\n",
    "    },\n",
    "    'VIN': {\n",
    "        'notes': [\n",
    "            'Not useful for predictions.'\n",
    "        ]\n",
    "    },\n",
    "    'price': {\n",
    "        'notes': [\n",
    "            'Target Field.',\n",
    "            'Need to deal with outliers.'\n",
    "        ]\n",
    "    },\n",
    "    'odometer': {\n",
    "        'notes': [\n",
    "            'Has an effect on price typically negative as mileage goes up.',\n",
    "            'Need to deal with outliers.'\n",
    "            'There are only a small percentage of values missing.'\n",
    "        ]\n",
    "    },\n",
    "    'manufacturer': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'There are empty values here and no easy way to determine them.',\n",
    "            'There are only a small percentage of values missing.'\n",
    "        ]\n",
    "    },\n",
    "    'model': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'There are empty values here and no easy way to determine them.',\n",
    "            'There are only a small percentage of values missing.',\n",
    "            'Free text field and there could be spelling mistakes or variations in order of words that aren\\'t easy to normalize.'\n",
    "        ]\n",
    "    },\n",
    "    'type': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'There are empty values here.',\n",
    "            'Can use manufacturer, model and year to fill in missing values'\n",
    "        ]\n",
    "    },\n",
    "    'drive': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'There are empty values here.',\n",
    "            'Can use manufacturer, model and year to fill in missing values'\n",
    "        ]\n",
    "    },\n",
    "    'transmission': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'There are empty values here.',\n",
    "            'There are only a small percentage of values missing.'\n",
    "        ]\n",
    "    },\n",
    "    'size': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'There are empty values here.',\n",
    "            'Can use manufacturer, model and year to fill in missing values'\n",
    "        ]\n",
    "    },\n",
    "    'cylinders': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'There are lots of empty values here.',\n",
    "            'Can use manufacturer, model and year to fill in missing values'\n",
    "        ]\n",
    "    },\n",
    "    'fuel': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'There are empty values here.',\n",
    "            'There are only a small percentage of values missing.'\n",
    "        ]\n",
    "    },\n",
    "    'paint_color': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'There are empty values here and no easy way to determine them.'\n",
    "        ]\n",
    "    },\n",
    "    'condition': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'There are empty values here and no easy way to determine them.'\n",
    "        ]\n",
    "    },\n",
    "    'title_status': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'There are empty values here.',\n",
    "            'There are only a small percentage of values missing.'\n",
    "        ]\n",
    "    },\n",
    "    'year': {\n",
    "        'notes': [\n",
    "            'Has an effect on price typically positive as value goes up since it\\'s a newer car.',\n",
    "            'Need to deal with outliers.'\n",
    "        ]\n",
    "    },\n",
    "    'state': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'Not really something dealer can control but can extract some useful information from this for other business decision making.'\n",
    "        ]\n",
    "    },\n",
    "    'region': {\n",
    "        'notes': [\n",
    "            'Has an effect on price.',\n",
    "            'Not really something dealer can control but can extract some useful information from this for other business decision making.'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "content += '### Analysis\\n\\n'\n",
    "content += \" There are a lot of categorical columns that will need to be encoded.\"\n",
    "content += \" There are also a lot of missing values for fields that will likely be important to the model.\" \n",
    "content += \" We'll have to impute where we can and drop where it won't affect the size of the dataset too much.\\n\\n\"\n",
    "\n",
    "\n",
    "dataReportDf = pd.read_excel(RESULT_FILE_PREFIX + STEP02_DATA_PREPARATION + 'data.frame.xlsx')\n",
    "content += '<table>\\n'\n",
    "content += '<tr>\\n'\n",
    "content += '<th></th>'\n",
    "content += '<th>Field</th>'\n",
    "content += '<th>Type</th>'\n",
    "content += '<th>Missing Value #</th>'\n",
    "content += '<th>Missing Value %</th>'\n",
    "content += '<th>Unique Value #</th>'\n",
    "content += '<th>Notes</th>'\n",
    "content += '</tr>\\n'\n",
    "i=1\n",
    "stage = 'raw'\n",
    "for f in fieldNotes:\n",
    "    fieldNode = fieldNotes[f]\n",
    "    fieldDf = dataReportDf.query('stage == @stage and column == @f').iloc[0]\n",
    "    dataType = fieldDf['data_type']\n",
    "    missingValueCount = fieldDf['na_value_count']\n",
    "    missingValuePct = fieldDf['na_value_pct']\n",
    "    uniqueValueCount = fieldDf['unq_value_count']\n",
    "    value = fieldNode['notes']\n",
    "    content += '<tr>\\n'\n",
    "    content += f'<td>{i}</td>'\n",
    "    content += f'<td>{f}</td>'\n",
    "    content += f'<td>{dataType}</td>'\n",
    "    content += f'<td>{missingValueCount}</td>'\n",
    "    content += f'<td>{missingValuePct}</td>'\n",
    "    content += f'<td>{uniqueValueCount}</td>'\n",
    "    processing = '</li>\\n<li>'.join(value)\n",
    "    content += f'<td><ul><li>{processing}</ul></td>'\n",
    "    content += '</tr>\\n'\n",
    "    i += 1\n",
    "content += '</table>\\n\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7547fef2-29de-4ad3-90d3-8d7b6edcfb4d",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a4a1a-705e-400f-94f7-c111785ae9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "content += '## Data Preparation\\n\\n'\n",
    "content += '### Cleanup Approach\\n\\n'\n",
    "dataPrepPipeline = readJson(RESULT_FILE_PREFIX + STEP02_DATA_PREPARATION + '.request.json')\n",
    "operations = dataPrepPipeline['operations']\n",
    "fieldProcessingPipeline = []\n",
    "for node in operations:\n",
    "    actions = []\n",
    "    fieldProcessingPipeline.append(actions)\n",
    "    operationName = node['operation']\n",
    "    configNode = node['config']\n",
    "    for f in configNode:\n",
    "        fieldConfigNode = configNode[f]\n",
    "        displayAction = 'Error'        \n",
    "        if operationName == 'drop':\n",
    "            displayAction = f'Drop the {f} feature column'\n",
    "        elif operationName == 'dropna':\n",
    "            displayAction = f'Drop rows where {f} is empty'\n",
    "        elif operationName == 'fillna':\n",
    "            replaceValue = fieldConfigNode['value']\n",
    "            displayAction = f'Fill rows where {f} is empty with \"{replaceValue}\"'\n",
    "        elif operationName == 'queryFilter':\n",
    "            query = fieldConfigNode['query']\n",
    "            displayAction = f'Drop rows meeting the critera \"{query}\"'\n",
    "        elif operationName == 'iqr':\n",
    "            q3Threshold = 0.75\n",
    "            q1Threshold = 0.25\n",
    "            if 'q3%' in fieldConfigNode:\n",
    "                q3Threshold = float(fieldConfigNode['q3%']) / 100\n",
    "            if 'q1%' in fieldConfigNode:\n",
    "                q1Threshold = float(fieldConfigNode['q1%']) / 100\n",
    "            displayAction = f'Drop rows not meeting criteria Q1[{q1Threshold}] <= {f} <= Q3[{q3Threshold}]'\n",
    "        elif operationName == 'toLowerCase':\n",
    "            displayAction = f'Convert {f} to lower case values'\n",
    "            targetField = f;\n",
    "            if 'field' in fieldConfigNode:\n",
    "                targetField = fieldConfigNode['field']\n",
    "                if targetField != f:\n",
    "                    displayAction += f' and store value in new field {targetField}'\n",
    "            if 'removeSpaces' in node:\n",
    "                if fieldConfigNode['removeSpaces'] == True:\n",
    "                    displayAction += f' and remove all spaces'\n",
    "        elif operationName == 'fillUsingMode':\n",
    "            lookupFields = ', '.join(fieldConfigNode['lookupFields'])\n",
    "            fillFields = ', '.join(fieldConfigNode['fillFields'])\n",
    "            displayAction = f'Using the fields {lookupFields} find teh mode() for those fields in the dataset and assign to {f}'\n",
    "        else:\n",
    "            raise Exception(f\"Unsupported operation: {operation}\")\n",
    "\n",
    "        actions.append(displayAction)\n",
    "\n",
    "content += '<table>\\n'\n",
    "content += '<tr>\\n'\n",
    "content += '<th>Step</th>'\n",
    "content += '<th>Processing</th>'\n",
    "content += '</tr>\\n'\n",
    "i=1\n",
    "for value in fieldProcessingPipeline:\n",
    "    content += '<tr>\\n'\n",
    "    content += f'<td>Step{i}</td>'\n",
    "    processing = '</li>\\n<li>'.join(value)\n",
    "    content += f'<td><ul><li>{processing}</ul></td>'\n",
    "    content += '</tr>\\n'\n",
    "    i += 1\n",
    "content += '</table>\\n\\n'\n",
    "\n",
    "content += '### Data Shape vs Processing Steps\\n\\n'\n",
    "content += '<table>\\n'\n",
    "img = addMarkdownImage('Row Counts', RESULT_FILE_PREFIX + STEP02_DATA_PREPARATION + 'row_count.png')\n",
    "content += f'<tr><td>{img}</td></tr>\\n'\n",
    "img = addMarkdownImage('Missing Value Count', RESULT_FILE_PREFIX + STEP02_DATA_PREPARATION + 'missing_count.png')\n",
    "content += f'<tr><td>{img}</td></tr>\\n'\n",
    "img = addMarkdownImage('Missing Value %', RESULT_FILE_PREFIX + STEP02_DATA_PREPARATION + 'missing_percentage.png')\n",
    "content += f'<tr><td>{img}</td></tr>\\n'\n",
    "img = addMarkdownImage('Missing Value %', RESULT_FILE_PREFIX + STEP02_DATA_PREPARATION + 'unique_values.png')\n",
    "content += f'<tr><td>{img}</td></tr>\\n'\n",
    "content += '</table>\\n\\n'\n",
    "\n",
    "\n",
    "content += printDataFrameInfo('Prepared Data Statistics', STEP02_DATA_PREPARATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ceaddb-c463-43c8-87c4-7d565ef9275f",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a080fd1f-ff71-4c09-b625-67ccc5d1cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "content += '## Modeling\\n\\n'\n",
    "modelReportDf = pd.read_excel(RESULT_FILE_PREFIX + STEP03_MODELING + 'model_report.data.frame.xlsx')\n",
    "useMetrics = ['Test MSE']\n",
    "useMetricsAscending = [True]\n",
    "bestModelDf = modelReportDf.sort_values(useMetrics, ascending=useMetricsAscending).iloc[0]\n",
    "bestModel = bestModelDf['Model']\n",
    "bestModelMetrics = []\n",
    "for k in useMetrics:\n",
    "    bestModelMetrics.append(f'**{k}={bestModelDf[k]}**')\n",
    "bestModelStats = ' and '.join(bestModelMetrics)\n",
    "categoricalFeatures = bestModelDf['Categorical Features']\n",
    "numericalFeatures = bestModelDf['Numerical Features']\n",
    "modelsTried = ', '.join(modelReportDf['Model'].values)\n",
    "content += '### Model Analysis\\n\\n'\n",
    "content += f'Using the following features \\n\\n'\n",
    "content += f'- Categorical={categoricalFeatures} \\n\\n'\n",
    "content += f'- Numerical={numericalFeatures} \\n\\n'\n",
    "content += f'we tried several regression models including **{modelsTried}** \\n\\n'\n",
    "modelPerformanceImage = addMarkdownImage('Model Performance', RESULT_FILE_PREFIX + STEP03_MODELING + 'performance.png')\n",
    "content += f'{modelPerformanceImage} \\n\\n'\n",
    "content += f'We have determined that the **best model** is **{bestModel}**'\n",
    "content += f' based on {bestModelStats}. We chose Test MSE because while it is more sensitive to outliers we\\'ve removed the outliers using IQR filtering. Had we not done this we would have used R2\\n\\n'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe9e76-8cf7-4242-9ec4-bf417b9773ee",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42281cd7-b8d7-4427-9146-fb2623fb86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "content += '## Evaluation\\n\\n'\n",
    "content += '### Feature Results\\n\\n'\n",
    "content += f'We will now show the importances of all the features across models\\n\\n'\n",
    "content += '<table>\\n'\n",
    "img = addMarkdownImage('Feature Importance', RESULT_FILE_PREFIX + STEP04_EVALUATION + 'coefficient.png')\n",
    "content += f'<tr><td>{img}</td></tr>\\n'\n",
    "content += '</table>\\n\\n'\n",
    "\n",
    "content += '### Feature Analysis\\n\\n'\n",
    "content += 'We can see from this that the models generally agree on what one would expect:\\n'\n",
    "content += '- Model also contributes positively. This makes sense as people prefer some cars over others, but it was hard to get exact models since the cardinality is so high. This can be inferred from combination of other features however\\n'\n",
    "content += '- As year goes up price goes up. This makes sense as you are getting a newer car\\n'\n",
    "content += '- As odometer goes up price goes down. This makes sense as you are getting a car with a lot more miles, wear and tear\\n'\n",
    "content += '- Interestingly fuel, cylinders, region and drive also feature prominently. Cylinders made sense because you pay for more horsepower. But region has heavy influence\\n'\n",
    "content += '- Looking at other features we can see prefernces for types (truck+pickups > sedan) and drive (4wd > fwd)\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553c17b9-7842-4517-9110-788a10f6995b",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2459d4c-f033-41c9-ac25-f511b28d4303",
   "metadata": {},
   "outputs": [],
   "source": [
    "content += '## Recommendations\\n\\n'\n",
    "\n",
    "content += '### Specific Features People Value\\n\\n'\n",
    "content += '<table>\\n'\n",
    "img = addMarkdownImage('Feature Importance', RESULT_FILE_PREFIX + STEP04_EVALUATION + 'pos.coeff.png')\n",
    "content += f'<tr><td>{img}</td></tr>\\n'\n",
    "content += '</table>\\n\\n'\n",
    "\n",
    "content += 'Do Prioritize:\\n\\n'\n",
    "content += '- Manufacturers=Toyota, Honda, Lexus, Tesla for the commonn brands\\n'\n",
    "content += '- Type=Pickups, Convertibles, Coupes and Trucks\\n'\n",
    "content += '- Size=Full Size, Mid Size\\n'\n",
    "content += '- Drive=4WD\\n'\n",
    "content += '- Cylinders=8\\n'\n",
    "content += '- Transmission=Manual\\n'\n",
    "content += '- Fuel=Diesel\\n'\n",
    "content += '- Title=Clean\\n\\n'\n",
    "content += 'This means move these to the front of your lot and they may benefit from a markup or marketing\\n\\n'\n",
    "\n",
    "\n",
    "content += 'If you are thinking of moving inventory the cars earn more in:\\n\\n'\n",
    "content += '- States=ak, mt, wa, co, ca...\\n'\n",
    "content += 'Perhaps you can move cars within these positive feature regions to maximize sale price\\n\\n'\n",
    "\n",
    "content += '### Specific Features People DO NOT Value\\n\\n'\n",
    "content += '<table>\\n'\n",
    "img = addMarkdownImage('Feature Importance', RESULT_FILE_PREFIX + STEP04_EVALUATION + 'neg.coeff.png')\n",
    "content += f'<tr><td>{img}</td></tr>\\n'\n",
    "content += '</table>\\n\\n'\n",
    "\n",
    "content += 'Do NOT Prioritize:\\n\\n'\n",
    "content += '- Manufacturers=Dodge, Kia, Nissan, Mitsubishi,  for the commonn brands\\n'\n",
    "content += '- Type=Sedan, Hatchback, SUV, Wagon\\n'\n",
    "content += '- Size=Compact, Sub-Compact\\n'\n",
    "content += '- Drive=FWD\\n'\n",
    "content += '- Cylinders=4 and lower\\n\\n'\n",
    "content += 'This means move these to the back of your lot it may be worthwhile getting rid of these quickly from your lot\\n\\n'\n",
    "\n",
    "content += 'If you are thinking of moving inventory the cars earn less in:\\n\\n'\n",
    "content += '- States=me, fl, ny, nh, il, ....\\n'\n",
    "content += 'Perhaps you can move cars with negative features to better performing regions to benefit from the markup\\n\\n'\n",
    "\n",
    "\n",
    "content += 'Using the charts above to make decisions about what types of features about the vehicle to prioritize in your inventory\\n\\n'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6134df5-55a1-425f-b4da-330f9236d3a4",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4280e-a4e5-4da1-9540-a37cf7261691",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(content))\n",
    "writeString2File(string2Write=content, path='./README.md',print2Screen=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
