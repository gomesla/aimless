### Multiple Default Model Comparisons
Comparing mutlipel models using default hyperparameters/settings we find.
#### Confusion Matrix
<a href="./analysis_results/module_17_01.step10.model_comparison.confusion_matrix.png" target="_blank"><img src="./analysis_results/module_17_01.step10.model_comparison.confusion_matrix.png"/></a>

#### Performance Metrics (Tables)
<a href="./analysis_results/module_17_01.step10.model_comparison.model_comparison_report.dataFrame.png" target="_blank"><img src="./analysis_results/module_17_01.step10.model_comparison.model_comparison_report.dataFrame.png"/></a>

#### Performance Metrics (Visualized)
<a href="./analysis_results/module_17_01.step10.model_comparison.model_comparison_graphs.png" target="_blank"><img src="./analysis_results/module_17_01.step10.model_comparison.model_comparison_graphs.png"/></a>

#### Analysis
- The best performing model is Logistic Regression with a score of 90.8116118908552% which is better than our baseline score of 88.61476767500653%.
- The worst performing model is Decision Tree with a score of 88.61476767500653% which is worse than our baseline score of 88.61476767500653%.
- The fastest performing model is KNN with a score of 89.03321419231105% which is better than our baseline score of 88.61476767500653%.
- The slowest performing model is SVC with a score of 90.5413651817627% which is better than our baseline score of 88.61476767500653%.

