{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions & Reusable Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# NOTE: This will fail for large dataset processing or complex model evaluation\n",
    "# Use the command below to run it in the background \n",
    "##############################\n",
    "# Source: https://www.maksimeren.com/post/screen-and-jupyter-a-way-to-run-long-notebooks-headless/\n",
    "# jupyter nbconvert --to notebook --execute prompt_III.template.ipynb --output=prompt_III.out.ipynb --ExecutePreprocessor.timeout=-1\n",
    "\n",
    "##############################\n",
    "# Library Imports\n",
    "##############################\n",
    "import copy\n",
    "import json\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import io\n",
    "from datetime import datetime\n",
    "from random import randint\n",
    "import timeit\n",
    "import datetime\n",
    "\n",
    "from IPython.core.getipython import get_ipython\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Frameworks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "\n",
    "\n",
    "# Plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn import metrics\n",
    "from sklearn import set_config\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, multilabel_confusion_matrix, ConfusionMatrixDisplay, confusion_matrix, accuracy_score, recall_score, precision_score, precision_recall_curve, roc_curve, RocCurveDisplay, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import make_column_transformer, make_column_selector, TransformedTargetRegressor, ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "\n",
    "##############################\n",
    "# Needed methods to bootstrap\n",
    "##############################\n",
    "def readFile(path):\n",
    "    with open(path) as f: \n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def readJson(path):\n",
    "    data = readFile(path)\n",
    "    return json.loads(data)\n",
    "\n",
    "##############################\n",
    "# Configuration + Flow control\n",
    "##############################\n",
    "BEGIN_RUN_DATETIME = datetime.datetime.now()\n",
    "SETTINGS = readJson('./settings.json')\n",
    "EXECUTION_MODE = SETTINGS['mode']\n",
    "DEV_MODE = \"development\" == EXECUTION_MODE\n",
    "print(f'Execution mode: {DEV_MODE}')\n",
    "USE_TARGET_ENCODER_FOR_HIGH_CARDINALTY = True\n",
    "EXECUTION_START_TIME = timeit.default_timer()\n",
    "RUNTIME_METRICS = {}\n",
    "\n",
    "##############################\n",
    "# Runtime Settings\n",
    "##############################\n",
    "set_config(display=\"diagram\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##############################\n",
    "# Constants\n",
    "##############################\n",
    "# https://seaborn.pydata.org/tutorial/color_palettes.html#sequential-color-palettes\n",
    "MAIN_PALETTE_QUALITATIVE = 'pastel'\n",
    "HIGHLIGHT_PALETTE_QUALITATIVE = 'Pastel2'\n",
    "MAIN_PALETTE_SEQUENTIAL = 'crest'\n",
    "IMAGE_DIR_SUFFIX = ''\n",
    "INPUT_FILE = './data/bank-additional-full.csv'\n",
    "RESULT_DIR = f'./analysis_results'    \n",
    "README_FILE = f'./README.md'\n",
    "\n",
    "CONFIG_NODE_KEY = 'config'\n",
    "DEFAULT_GRID_SEARCH_SCORING_TYPES = ['accuracy']\n",
    "BASELINE_MODEL_2_TRY = {\n",
    "    'Baseline (DummyClassifier)': {\n",
    "        'model': DummyClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'model__strategy': ['most_frequent']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "SIMPLE_MODEL_2_TRY = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42),\n",
    "        'params': {\n",
    "        }\n",
    "    }\n",
    "}\n",
    "DEFAULT_MODELS_2_TRY = {\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "        }\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42),\n",
    "        'params': {\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'params': {\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        'model': SVC(random_state=42),\n",
    "        'params': {}\n",
    "    }\n",
    "}        \n",
    "GRID_SEARCH_MODELS_2_TRY = {\n",
    "    'KNN': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'model__n_neighbors': range(1, 75, 1),\n",
    "            'model__weights': ['uniform', 'distance']\n",
    "        }\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42),\n",
    "        'params': {\n",
    "            'model__penalty': ['l2', 'elasticnet'],\n",
    "            'model__C': np.linspace(0.1, 1, num=10)\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'model__max_depth': range(1, 11),\n",
    "            'model__criterion': ['gini', 'entropy', 'log_loss']\n",
    "        }\n",
    "    },\n",
    "    'SVC': {\n",
    "        'model': SVC(random_state=42),\n",
    "        'params': {\n",
    "            'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'model__C': np.linspace(0.1, 1, num=10)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "if DEV_MODE:\n",
    "    RESULT_DIR =  f'{RESULT_DIR}.{EXECUTION_MODE}'\n",
    "    INPUT_FILE = './data/bank-additional.csv'\n",
    "    README_FILE = f'./README.{EXECUTION_MODE}.md'\n",
    "    GRID_SEARCH_MODELS_2_TRY['KNN']['params'] = {\n",
    "        'model__n_neighbors': [5]\n",
    "    }\n",
    "    GRID_SEARCH_MODELS_2_TRY['Logistic Regression']['params'] = {\n",
    "        'model__penalty': ['l2']\n",
    "    }\n",
    "    GRID_SEARCH_MODELS_2_TRY['Decision Tree']['params'] = {\n",
    "        'model__max_depth': [5],\n",
    "        'model__criterion': ['log_loss']\n",
    "    }\n",
    "    GRID_SEARCH_MODELS_2_TRY['SVC']['params'] = {\n",
    "        'model__kernel': ['linear']\n",
    "    }\n",
    "\n",
    "RESULT_FILE_PREFIX = RESULT_DIR +'/module_17_01.'\n",
    "IMAGE_PREFIX = RESULT_FILE_PREFIX\n",
    "\n",
    "IGNORE_FEATURES = {}\n",
    "\n",
    "STEP03_PREFIX = 'step03.data_understanding.'\n",
    "STEP05_PREFIX = 'step05.engineering_features.'\n",
    "STEP07_PREFIX = 'step07.baseline_model.'\n",
    "STEP08_PREFIX = 'step08.simple_model.'\n",
    "STEP09_PREFIX = 'step09.score_model.'\n",
    "STEP10_PREFIX = 'step10.model_comparison.'\n",
    "STEP11_PREFIX = 'step11.improving_model.'\n",
    "STEP12_PREFIX = 'step12.final_analysis.'\n",
    "\n",
    "FEATURES_BANK_CLIENT_DATA = [\n",
    "    'age', \n",
    "    'job',\n",
    "    'marital',\n",
    "    'education',\n",
    "    'default',\n",
    "    'housing',\n",
    "    'loan',\n",
    "    'contact',\n",
    "    'month',\n",
    "    'day_of_week',\n",
    "    'duration'\n",
    "]\n",
    "FEATURES_OTHER = [\n",
    "    'campaign',\n",
    "    'pdays',\n",
    "    'previous',\n",
    "    'poutcome'\n",
    "]\n",
    "FEATURES_SOCIAL_ECONOMIC = [\n",
    "    'emp.var.rate',\n",
    "    'cons.price.idx',\n",
    "    'cons.conf.idx',\n",
    "    'euribor3m',\n",
    "    'nr.employed'\n",
    "]\n",
    "TARGET_FIELD = 'y'\n",
    "\n",
    "\n",
    "EXPERIMENT1_FEATURES = FEATURES_BANK_CLIENT_DATA.copy()\n",
    "EXPERIMENT1_FEATURES += TARGET_FIELD\n",
    "\n",
    "EXPERIMENT2_FEATURES = EXPERIMENT1_FEATURES.copy()\n",
    "EXPERIMENT2_FEATURES += FEATURES_OTHER\n",
    "\n",
    "EXPERIMENT3_FEATURES = EXPERIMENT2_FEATURES.copy()\n",
    "EXPERIMENT3_FEATURES += FEATURES_SOCIAL_ECONOMIC\n",
    "\n",
    "EXPERIMENT4_FEATURES = EXPERIMENT3_FEATURES.copy()\n",
    "EXPERIMENT4_FEATURES.remove('duration')\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    'experiment1': {\n",
    "        'name': 'Only Bank Client Data',\n",
    "        'features':  EXPERIMENT1_FEATURES,\n",
    "        'description': 'Experiment using bank client data features including duration'\n",
    "    },\n",
    "    'experiment2': {\n",
    "        'name': 'Bank Client Data + Other',\n",
    "        'features': EXPERIMENT2_FEATURES,\n",
    "        'description': 'Experiment using bank client data features, other features including duration',\n",
    "    },\n",
    "    'experiment3': {\n",
    "        'name': 'Bank Client Data + Other + Social and Economic',\n",
    "        'features': EXPERIMENT3_FEATURES,\n",
    "        'description': 'Experiment using bank client data features, other features, social and economic features including duration',\n",
    "    },\n",
    "    'experiment4': {\n",
    "        'name': 'Bank Client Data + Other + Social and Economic without Duraton',\n",
    "        'features': EXPERIMENT4_FEATURES,\n",
    "        'description': 'Experiment using all features except duration.\\nAs part of the data description above we are told:\\n' +\n",
    "            '```\\n' +\n",
    "            'duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y=\"no\"). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model\\n' +\n",
    "            '```\\n',\n",
    "        'printDistributionGraphs': True\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "if not os.path.exists(RESULT_DIR):\n",
    "    os.makedirs(RESULT_DIR)\n",
    "\n",
    "##############################\n",
    "# Common global methods\n",
    "##############################\n",
    "def addMarkdownImage(name, path, asMarkdown=False):\n",
    "    if asMarkdown:\n",
    "        out = f'![{name}]({IMAGE_PREFIX}{path})'\n",
    "    else:\n",
    "        out = f'<a href=\"{IMAGE_PREFIX}{path}\" target=\"_blank\"><img src=\"{IMAGE_PREFIX}{path}\"/></a>'\n",
    "\n",
    "    return out\n",
    "\n",
    "def printDataFrameInfo(name, stage):\n",
    "    out = ''\n",
    "    out += f'### {name}\\n\\n'\n",
    "    out += '<table>'\n",
    "    out += '<tr><th>info()</th><th>describe()</th></tr>'\n",
    "\n",
    "    prefix = RESULT_FILE_PREFIX + stage\n",
    "    rawDfInfo = readFile(prefix + 'data.info.txt')\n",
    "    rawDfDescribe = readFile(prefix + 'data.describe.txt')\n",
    "    imgPath = prefix + 'data.distribution.png'\n",
    "    \n",
    "    rawDfStatsImage = addMarkdownImage(name, imgPath)\n",
    "    out += '<tr>'\n",
    "    out += f'<td><pre>{rawDfInfo}</pre></td>'\n",
    "    out += f'<td><pre>{rawDfDescribe}</pre></td>'\n",
    "    out += '</tr>'\n",
    "    out += '<tr>'\n",
    "    out += f'<td colspan=\"2\">\\n{rawDfStatsImage}\\n</td></tr>'\n",
    "    out += '</tr>'\n",
    "    out += '</table>\\n\\n'\n",
    "\n",
    "    return out\n",
    "\n",
    "def writeDataFrame2Excel(inputDf, name):\n",
    "    extension = '.dataFrame.xlsx'\n",
    "    if name[-1] == '.':\n",
    "        extension = 'dataFrame.xlsx'\n",
    "    with pd.ExcelWriter(RESULT_FILE_PREFIX + name + extension) as writer:\n",
    "        inputDf.to_excel(writer)\n",
    "        \n",
    "def writeString2File(string2Write, path, print2Screen = False):\n",
    "    if print2Screen:\n",
    "        print(string2Write)\n",
    "    with open(path, \"w\") as text_file:\n",
    "        text_file.write(str(string2Write))\n",
    "\n",
    "# NOTE: Need this to avoid value truncation in cells\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "def dataFrame2Html(inputDf, path, print2Screen = False):\n",
    "    string2write = inputDf.to_html(index=False)\n",
    "    writeString2File(string2write, IMAGE_PREFIX + path + '.dataFrame.html', print2Screen)\n",
    "    \n",
    "    \n",
    "def dataFrame2Image(inputDf, path, baseHeight=480, height_per_row=20, char_limit=30, height_padding=10, baseWidth=1200):\n",
    "    total_height = 0 + height_per_row\n",
    "    for x in range(inputDf.shape[0]):\n",
    "        total_height += height_per_row\n",
    "    for x in range(inputDf.shape[0]):\n",
    "        for y in range(inputDf.shape[1]):\n",
    "            bumpHeight = False\n",
    "            currChars = len(str(inputDf.iloc[x][y]))\n",
    "            if currChars > char_limit:\n",
    "                bumpHeight = True\n",
    "            if bumpHeight:\n",
    "                total_height += (height_padding) * (currChars / char_limit)\n",
    "\n",
    "    height = total_height\n",
    "    width = baseWidth\n",
    "    layout = {\n",
    "        'height': height, \n",
    "        'width': width,\n",
    "        'margin': {'r': 1, 'l': 1, 't': 1, 'b': 1}\n",
    "    }    \n",
    "    fig = go.Figure(data=[\n",
    "            go.Table(\n",
    "                header=dict(values=list(inputDf.columns), fill_color='paleturquoise', align='left'),\n",
    "                cells=dict(values=inputDf.transpose().values.tolist(), fill_color='lavender', align='left')\n",
    "            )], layout=layout)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    pio.write_image(fig, IMAGE_PREFIX + path + '.dataFrame.png', scale=1, width=width, height=total_height)\n",
    "\n",
    "def getType(row, orginalDf):\n",
    "    return str(orginalDf.dtypes[row['column']])\n",
    "    \n",
    "def getUniqueCounts(row, orginalDf):\n",
    "    return len(orginalDf[row['column']].unique())\n",
    "\n",
    "def writeDataFrameDetails(data, targetField, fileNameSuffix, titleSuffix='', width=480, height=400, bins=100, writeInfo=False, writeDescribe=False, highlightColumns=[], palette=MAIN_PALETTE_QUALITATIVE):\n",
    "    buffer = io.StringIO()\n",
    "    data.info(verbose=True, buf=buffer, show_counts=True)\n",
    "    useFileNameSuffix = fileNameSuffix\n",
    "    if useFileNameSuffix.endswith(\".\"):\n",
    "        useFileNameSuffix = useFileNameSuffix[:-1]\n",
    "    if writeInfo:\n",
    "        writeString2File(buffer.getvalue(), RESULT_FILE_PREFIX + useFileNameSuffix + 'data.info.txt')\n",
    "    if writeDescribe:\n",
    "        writeString2File(data.describe(), RESULT_FILE_PREFIX + useFileNameSuffix + 'data.describe.txt')\n",
    "    \n",
    "    plotDistribution4Fields = list(data.select_dtypes(include=[np.number]).columns.values)\n",
    "    if targetField in plotDistribution4Fields:\n",
    "        plotDistribution4Fields.remove(targetField)\n",
    "    graphsPerRow = len(plotDistribution4Fields)\n",
    "    if graphsPerRow > 0:\n",
    "        widthInches = width * graphsPerRow/100\n",
    "        heightInches = height * 2/100\n",
    "        plt.clf()\n",
    "        plt.figure()\n",
    "        fig, ax = plt.subplots(2, len(plotDistribution4Fields), squeeze=False, figsize=(widthInches, heightInches))\n",
    "        subPlotRow = 0\n",
    "        subPlotCol = 0\n",
    "        for field in plotDistribution4Fields:\n",
    "            palette2use = palette\n",
    "            if field in highlightColumns:\n",
    "                palette2use = HIGHLIGHT_PALETTE_QUALITATIVE\n",
    "            axSub1 = sns.boxplot(ax=ax[0,subPlotCol], data=data[[field]], palette=palette2use)\n",
    "            axSub2 = sns.histplot(ax=ax[1,subPlotCol], data=data, y=field, palette=palette2use, \n",
    "                                  hue=targetField, bins=bins, stat='percent', multiple=\"stack\")\n",
    "            subPlotCol += 1\n",
    "\n",
    "        fig.suptitle('Data Distribution (Numeric Fields)' + titleSuffix)\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(RESULT_FILE_PREFIX + useFileNameSuffix + '.numeric.data.distribution.png')\n",
    "\n",
    "    plotDistribution4Fields = list(data.select_dtypes(exclude=[np.number]).columns.values)\n",
    "    if targetField in plotDistribution4Fields:\n",
    "        plotDistribution4Fields.remove(targetField)\n",
    "    graphsPerRow = len(plotDistribution4Fields)\n",
    "    if graphsPerRow > 0:\n",
    "        widthInches = width * graphsPerRow/100\n",
    "        heightInches = height * 2/100\n",
    "        plt.clf()\n",
    "        plt.figure()\n",
    "        fig, ax = plt.subplots(1, len(plotDistribution4Fields), figsize=(widthInches, heightInches))\n",
    "        subPlotRow = 0\n",
    "        subPlotCol = 0\n",
    "        for field in plotDistribution4Fields:\n",
    "            palette2use = palette\n",
    "            if field in highlightColumns:\n",
    "                palette2use = HIGHLIGHT_PALETTE_QUALITATIVE\n",
    "            axSub1 = sns.histplot(ax=ax[subPlotCol], data=data, y=field, palette=palette2use,\n",
    "                                  hue=targetField, bins=bins, stat='percent', multiple=\"stack\")\n",
    "            subPlotCol += 1\n",
    "\n",
    "        fig.suptitle('Data Distribution (Categorical Fields)' + titleSuffix)\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(RESULT_FILE_PREFIX + useFileNameSuffix + '.categorical.data.distribution.png')\n",
    "    \n",
    "def addMetadataStatistics(stage, inputDf, \n",
    "                          dataReportDf = pd.DataFrame(columns = [\n",
    "                              'stage', \n",
    "                              'row_count', \n",
    "                              'column', \n",
    "                              'data_type', \n",
    "                              'na_value_count', \n",
    "                              'na_value_pct', \n",
    "                              'unq_value_count'])):\n",
    "    naSeries = inputDf.isna().sum()\n",
    "    numRows = inputDf.shape[0]\n",
    "    \n",
    "    metaDf = pd.DataFrame()\n",
    "    metaDf['column'] = naSeries.index\n",
    "    metaDf['data_type'] = metaDf.apply(getType, orginalDf=inputDf, axis=1)\n",
    "    metaDf['na_value_count']= naSeries.values\n",
    "    metaDf['na_value_pct']= metaDf['na_value_count'] * 100 / numRows\n",
    "    metaDf['unq_value_count'] = metaDf.apply(getUniqueCounts, orginalDf=inputDf, axis=1)\n",
    "    metaDf['stage'] = stage\n",
    "    metaDf['row_count'] = numRows\n",
    "\n",
    "    for index, row in metaDf.iterrows():\n",
    "        dataReportDf.loc[dataReportDf.shape[0]] = row\n",
    "    return dataReportDf\n",
    "\n",
    "def doDrop(operationNode, inputDf, dataReportDf):\n",
    "    configNode = operationNode[CONFIG_NODE_KEY]\n",
    "    keys = []\n",
    "    for k in configNode:\n",
    "        keys.append(k)\n",
    "        inputDf = inputDf.drop(k, axis=1)\n",
    "    return inputDf, dataReportDf\n",
    "    \n",
    "def doQueryFiltering(operationNode, inputDf, dataReportDf):\n",
    "    outputDf = inputDf\n",
    "    configNode = operationNode[CONFIG_NODE_KEY]\n",
    "    for k in configNode:\n",
    "        node = configNode[k]\n",
    "        query = node['query']\n",
    "        outputDf = outputDf.query(query)\n",
    "        dataReportDf = addMetadataStatistics(f'query({k})', outputDf, dataReportDf)\n",
    "    return outputDf, dataReportDf\n",
    "\n",
    "def doDropDuplicates(operationNode, inputDf, dataReportDf):\n",
    "    outputDf = inputDf\n",
    "    outputDf = outputDf.drop_duplicates()\n",
    "    dataReportDf = addMetadataStatistics(f'drop duplicates', outputDf, dataReportDf)\n",
    "    return outputDf, dataReportDf\n",
    "    \n",
    "def preProcessData(request, inputDf, dataReportDf):\n",
    "    # Copy once then use same for all transforms\n",
    "    responseDf = inputDf.copy()\n",
    "    operations = request['operations']\n",
    "    for node in operations:\n",
    "        operationName = node['operation']\n",
    "        print(f'Processing: {operationName}')\n",
    "        if operationName == 'drop':\n",
    "            responseDf, dataReportDf = doDrop(node, responseDf, dataReportDf)\n",
    "        elif operationName == 'queryFilter':\n",
    "            responseDf, dataReportDf = doQueryFiltering(node, responseDf, dataReportDf)\n",
    "        elif operationName == 'dropDuplicates':\n",
    "            responseDf, dataReportDf = doDropDuplicates(node, responseDf, dataReportDf)\n",
    "        else:\n",
    "            raise Exception(f\"Unsupported operation: {operation}\")\n",
    "    \n",
    "    return responseDf, dataReportDf\n",
    "    \n",
    "def showBarPlot(request, data, xColumn, yColumn, colorColumn, path, xLogScale=False, yLogScale=False, width=1200, height=600, dataLabelRotation=0, moveLegendBotttom=False, palette=MAIN_PALETTE_QUALITATIVE):\n",
    "    labels = request['labels']\n",
    "    xAxesLabel = labels[xColumn]\n",
    "    if xLogScale:\n",
    "        xAxesLabel += ' (Log Scale)'\n",
    "    yAxesLabel = labels[yColumn]\n",
    "    if yLogScale:\n",
    "        yAxesLabel += ' (Log Scale)'\n",
    "    title = yAxesLabel + ' vs ' + xAxesLabel\n",
    "    barWidthPixels = 80\n",
    "    if data.shape[0] > 0:\n",
    "        barWidthInches = barWidthPixels / 100\n",
    "        # Width of graph is number of rows * bar_width \n",
    "        widthInches = math.ceil(width / 100)\n",
    "        heightInches = math.ceil(height / 100)\n",
    "        legendLocation='lower left'\n",
    "        bboxAnchor=(0, -0.5)\n",
    "        plt.clf()\n",
    "        plt.figure()\n",
    "        axSub = sns.barplot(data=data, x=xColumn, y=yColumn, hue=colorColumn, \n",
    "                         palette=palette, width=barWidthInches)\n",
    "        axSub.set_title(title)\n",
    "        axSub.set(xlabel=xAxesLabel, ylabel=yAxesLabel)\n",
    "        for bars_group in axSub.containers: \n",
    "            axSub.bar_label(bars_group, padding=3, fontsize=8, rotation=dataLabelRotation, label_type='center')\n",
    "        if yLogScale:\n",
    "            plt.yscale('log')\n",
    "        if xLogScale:\n",
    "            plt.xscale('log')\n",
    "        if moveLegendBotttom:\n",
    "            sns.move_legend(axSub, legendLocation, bbox_to_anchor=bboxAnchor)\n",
    "        axSub.figure.set_size_inches(widthInches, heightInches)\n",
    "        \n",
    "        plt.savefig(path, bbox_inches='tight')\n",
    "        \n",
    "def showDataPreparationBarPlot(request, prefix, data, xColumn, yColumn, colorColumn, fileSuffix, xLogScale=False, yLogScale=False, width=1200, height=600):\n",
    "    filePrefix = RESULT_FILE_PREFIX + prefix\n",
    "    showBarPlot(request=request, data=data, xColumn=xColumn, yColumn=yColumn, colorColumn=colorColumn, \n",
    "                path=filePrefix + fileSuffix, xLogScale=xLogScale, yLogScale=yLogScale, width=width, height=height, dataLabelRotation=90, moveLegendBotttom=True)\n",
    "\n",
    "def displayStats(request, prefix, dataReportDf, restrictToStages = []):\n",
    "    suffix = ''\n",
    "    if(len(restrictToStages) > 0):\n",
    "        suffix += '-'.join(restrictToStages) + '.'\n",
    "    labels = request['labels']\n",
    "    filteredDf = dataReportDf\n",
    "    if len(restrictToStages) > 0:\n",
    "        filteredDf = dataReportDf.loc[dataReportDf['stage'].isin(restrictToStages)]\n",
    "\n",
    "    columnNames = list(filteredDf['column'].value_counts().index)\n",
    "    if 'excludeColumnsFromReport' in request:\n",
    "        excludeColumns = request['excludeColumnsFromReport']\n",
    "        for k in excludeColumns:\n",
    "            if k in columnNames:\n",
    "                columnNames.remove(k)\n",
    "    filteredDf = filteredDf.loc[filteredDf['column'].isin(columnNames)]\n",
    "    \n",
    "    xColumn = 'column'\n",
    "    colorColumn = 'stage'\n",
    "    \n",
    "    yColumn = 'row_count'\n",
    "    data = filteredDf.loc[filteredDf['column'] == columnNames[0]]\n",
    "    showDataPreparationBarPlot(request=request, prefix=prefix, data=data, xColumn=xColumn, yColumn=yColumn, colorColumn=colorColumn, \n",
    "                               fileSuffix=suffix + 'row_count.png', height=800)\n",
    "    \n",
    "    yColumn = 'na_value_count'\n",
    "    data = filteredDf[filteredDf[yColumn] != 0]\n",
    "    showDataPreparationBarPlot(request=request, prefix=prefix, data=data, xColumn=xColumn, yColumn=yColumn, colorColumn=colorColumn, \n",
    "                               fileSuffix=suffix + 'missing_count.png', yLogScale=True, height=800, width=2400)\n",
    "\n",
    "    yColumn = 'na_value_pct'\n",
    "    data = filteredDf[filteredDf[yColumn] != 0]\n",
    "    showDataPreparationBarPlot(request=request, prefix=prefix, data=data, xColumn=xColumn, yColumn=yColumn, colorColumn=colorColumn, \n",
    "                               fileSuffix=suffix + 'missing_percentage.png', yLogScale=True, height=800, width=2400)\n",
    "\n",
    "    yColumn = 'unq_value_count'\n",
    "    data = filteredDf.loc[filteredDf['data_type'] == 'object']\n",
    "    showDataPreparationBarPlot(request=request, prefix=prefix, data=data, xColumn=xColumn, yColumn=yColumn, colorColumn=colorColumn, \n",
    "                               fileSuffix=suffix + 'unique_values.png', yLogScale=True, height=800, width=2400)\n",
    "\n",
    "def encodeAndAddCategoricalColumns(inputDf, targetField, categoricalFeatures):\n",
    "    lowCardinalityFeatures = []\n",
    "    highCardinalityFeatures = []\n",
    "\n",
    "    renamedFields = {}\n",
    "    for cf in categoricalFeatures:\n",
    "        if cf != targetField:\n",
    "            unqValues = len(inputDf[cf].value_counts())\n",
    "            if unqValues > 255:\n",
    "                renamedFields[cf] = 'encoded_' + cf\n",
    "                highCardinalityFeatures.append(cf)\n",
    "            else:\n",
    "                lowCardinalityFeatures.append(cf)\n",
    "            \n",
    "    transformerSet = []\n",
    "    if(len(lowCardinalityFeatures) > 0):\n",
    "        transformerSet.append(('categorical_low_cardinality', OneHotEncoder(drop=\"if_binary\", sparse_output=False), lowCardinalityFeatures))\n",
    "\n",
    "    enhancedDf = inputDf\n",
    "    \n",
    "    # https://towardsdatascience.com/dealing-with-categorical-variables-by-using-target-encoder-a0f1733a4c69\n",
    "    if(len(highCardinalityFeatures) > 0):\n",
    "        if USE_TARGET_ENCODER_FOR_HIGH_CARDINALTY:\n",
    "            transformerSet.append(('categorical_high_cardinality', TargetEncoder(), highCardinalityFeatures))\n",
    "        else:\n",
    "            labelEncoder = LabelEncoder()\n",
    "            for hcf in highCardinalityFeatures:\n",
    "                enhancedDf['encoded_' + hcf] = labelEncoder.fit_transform(enhancedDf[hcf])\n",
    "\n",
    "    \n",
    "    \n",
    "    columnTransformer = ColumnTransformer(transformerSet, verbose_feature_names_out=False)\n",
    "    columnTransformer.set_output(transform='pandas')\n",
    "    \n",
    "\n",
    "    \n",
    "    encodedDf = columnTransformer.fit_transform(enhancedDf, enhancedDf[targetField])\n",
    "    encodedFeatureNames = columnTransformer.get_feature_names_out()\n",
    "    encodedDf = encodedDf[encodedFeatureNames]\n",
    "    if USE_TARGET_ENCODER_FOR_HIGH_CARDINALTY:\n",
    "        encodedDf.rename(columns=renamedFields, inplace=True)\n",
    "    enhancedDf = enhancedDf.join(encodedDf)\n",
    "    return enhancedDf\n",
    "def generatePercentCompositionBarReport4Columns(params, df2Use, targetField, columns, fileSuffix=None, baseWidth=640, baseHeight=480, highlightColumns=[], palette=MAIN_PALETTE_QUALITATIVE):\n",
    "    normalizedColumn = 'percent'\n",
    "    countColumn = 'count_1'\n",
    "    colorColumn = targetField\n",
    "\n",
    "    debug = False\n",
    "    if params != None:\n",
    "        if 'debug' in params:\n",
    "            debug = params['debug']\n",
    "\n",
    "    plotsNeeded = len(columns)\n",
    "    if targetField in columns:\n",
    "        plotsNeeded -= 1\n",
    "    width = (baseWidth / 100) * plotsNeeded\n",
    "    height = (baseHeight / 100) \n",
    "    barWidthInches = 80 / 100\n",
    "    dataLabelRotation = 90\n",
    "\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(2, plotsNeeded, squeeze=False, figsize=(width, height))\n",
    "    \n",
    "    graphIndex = 0\n",
    "    for groupByColumn in columns:\n",
    "        if groupByColumn != targetField:\n",
    "            palette2Use = palette\n",
    "            if groupByColumn in highlightColumns:\n",
    "                palette2Use = HIGHLIGHT_PALETTE_QUALITATIVE\n",
    "            baseDf = df2Use.copy()\n",
    "            baseDf[countColumn] = 1\n",
    "            currDf = baseDf.groupby([groupByColumn, colorColumn])[countColumn].count().reset_index()\n",
    "            denomDf = baseDf.groupby([groupByColumn])[countColumn].count().reset_index()\n",
    "            #print(denomDf.info())\n",
    "            #print(denomDf)\n",
    "            currDf = currDf.merge(denomDf, how='inner', on=groupByColumn)\n",
    "            currDf[normalizedColumn] = round(100 * currDf[countColumn + '_x'] / currDf[countColumn + '_y'], 2)\n",
    "    \n",
    "            xAxesLabel = groupByColumn\n",
    "            yColumn = normalizedColumn\n",
    "            yAxesLabel = yColumn\n",
    "            title = f'Distribution ({yAxesLabel}) - ' + groupByColumn\n",
    "            axSub = sns.barplot(ax=ax[0, graphIndex], x=groupByColumn, y=normalizedColumn, data=currDf, hue=targetField, palette=palette2Use)\n",
    "            axSub.set_title(title)\n",
    "            axSub.set(xlabel=xAxesLabel, ylabel=yAxesLabel)\n",
    "            axSub.tick_params(axis='x', labelrotation=45)\n",
    "            sns.move_legend(axSub, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "            for bars_group in axSub.containers: \n",
    "                axSub.bar_label(bars_group, padding=3, fontsize=8, rotation=dataLabelRotation, label_type='center')\n",
    "\n",
    "            yAxesLabel = 'count'\n",
    "            title = f'Distribution ({yAxesLabel}) - ' + groupByColumn\n",
    "            axSub2 = sns.barplot(ax=ax[1, graphIndex], x=groupByColumn, y=countColumn + '_x', data=currDf, hue=targetField, palette=palette2Use)\n",
    "            axSub2.set_title(title)\n",
    "            axSub2.set(xlabel=xAxesLabel, ylabel=yAxesLabel)\n",
    "            axSub2.tick_params(axis='x', labelrotation=45)\n",
    "            sns.move_legend(axSub2, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "            for bars_group in axSub2.containers: \n",
    "                axSub2.bar_label(bars_group, padding=3, fontsize=8, rotation=dataLabelRotation, label_type='center')\n",
    "    \n",
    "            graphIndex +=1\n",
    "            \n",
    "            if debug:\n",
    "                display(currDf)\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    if fileSuffix != None:\n",
    "        plt.savefig(IMAGE_PREFIX + fileSuffix + '.png')\n",
    "    \n",
    "def runAnalysis(name, filePrefix, data, targetField, models2Try, directModel=False, scoringTypes=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'], sortBy='test score'):\n",
    "    featureFields = list(data.columns.values)\n",
    "    featureFields.remove(targetField);\n",
    "    X = data[featureFields]\n",
    "    y = data[[targetField]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    labels = list(y[targetField].value_counts().index)\n",
    "    \n",
    "    # Reporting\n",
    "    reportDf = pd.DataFrame(columns = ['experiment', 'model', 'scoring_type', 'train score', 'test score', 'average fit time', 'grid_search_train_wall_time', 'best_params'])\n",
    "    importantFeatureDf = pd.DataFrame(columns = ['feature','votes', 'sum_coefficients' ,'coefficients'])\n",
    "    importantFeatures = {}\n",
    "    featureCoefficientMappings = {}\n",
    "    for f in featureFields:\n",
    "        importantFeatures[f] = {\n",
    "            'votes': 0,\n",
    "            'coefficients': []\n",
    "        }\n",
    "        featureCoefficientMappings[f] = {}\n",
    "        for mk in models2Try:\n",
    "            featureCoefficientMappings[f][mk] = {}\n",
    "            for scoringType in scoringTypes:\n",
    "                featureCoefficientMappings[f][mk][scoringType] = None\n",
    "    \n",
    "    # Data spread\n",
    "    targetClassComposition = y[targetField].value_counts(normalize=True)\n",
    "    classBalanceDf = pd.DataFrame(columns = ['class_name', 'class_value', 'class_percent'])\n",
    "    classBalanceDf['class_name'] = name\n",
    "    classBalanceDf['class_value'] = targetClassComposition.index\n",
    "    classBalanceDf['class_percent'] = targetClassComposition.values\n",
    "    \n",
    "    # Model Building\n",
    "    plt.clf()\n",
    "    plt.figure()\n",
    "    width = (320 / 100) * len(models2Try)\n",
    "    height = (240 / 100)\n",
    "    fig, ax = plt.subplots(1, len(models2Try), squeeze=False, figsize=(width, height))\n",
    "    mkIndex = 0\n",
    "    \n",
    "    for mk in models2Try:\n",
    "        node = models2Try[mk]\n",
    "        model = node['model']\n",
    "        params = node['params']\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        for scoringType in scoringTypes:\n",
    "            model2Use = pipeline\n",
    "            if directModel == False:\n",
    "                model2Use = GridSearchCV(pipeline, param_grid=params, scoring=scoringType)\n",
    "\n",
    "            display(model2Use)\n",
    "            startTime = timeit.default_timer()\n",
    "            model2Use.fit(X_train, y_train)\n",
    "            fitWallTime = timeit.default_timer() - startTime\n",
    "\n",
    "            if directModel:\n",
    "                bestEstimator = pipeline\n",
    "                bestParams = {}\n",
    "                meanFitTime = fitWallTime\n",
    "            else:\n",
    "                bestEstimator = model2Use.best_estimator_\n",
    "                bestParams = model2Use.best_params_\n",
    "                meanFitTime = model2Use.cv_results_['mean_fit_time'].mean()\n",
    "                \n",
    "            y_test_prediction = bestEstimator.predict(X_test)\n",
    "            trainScore = accuracy_score(y_train, bestEstimator.predict(X_train))\n",
    "            testScore = accuracy_score(y_test,y_test_prediction)\n",
    "\n",
    "            if 'accuracy' == scoringType:\n",
    "                disp = ConfusionMatrixDisplay.from_predictions(y_test, y_test_prediction, cmap=MAIN_PALETTE_SEQUENTIAL, include_values=True)\n",
    "                disp.plot(ax=ax[0, mkIndex])\n",
    "                title_font = {'size':'8'}  # Adjust to fit\n",
    "                disp.ax_.set_title(mk, fontdict=title_font)\n",
    "                disp.im_.colorbar.remove()\n",
    "                mkIndex += 1\n",
    "\n",
    "            \n",
    "            # https://www.geeksforgeeks.org/how-to-identify-the-most-informative-features-for-scikit-learn-classifiers/\n",
    "            try:\n",
    "                model = bestEstimator['model']\n",
    "                selector = SelectFromModel(model, prefit=True)\n",
    "                selectedFeatures = selector.get_support()\n",
    "                importances = []\n",
    "                try:\n",
    "                    importances = model.coef_[0]\n",
    "                except:\n",
    "                    importances = []\n",
    "                \n",
    "                featureIndex = 0\n",
    "                for f in featureFields:\n",
    "                    if selectedFeatures[featureIndex] == True:\n",
    "                        importantFeatures[f]['votes'] += 1\n",
    "                        coeff = None\n",
    "                        if len(importances) > featureIndex:\n",
    "                            coeff = importances[featureIndex]\n",
    "                            importantFeatures[f]['coefficients'].append(coeff)\n",
    "                        featureCoefficientMappings[f][mk][scoringType] = coeff\n",
    "                    featureIndex += 1\n",
    "            except Exception as error:\n",
    "                bestFeatures = [f'<NotAvailable>']\n",
    "\n",
    "            reportDf.loc[reportDf.shape[0]] = [name, mk, scoringType, trainScore, testScore, meanFitTime, fitWallTime, json.dumps(bestParams).replace('model__', '')]\n",
    "\n",
    "    \n",
    "    dataSetSuffix = f'{name}.'\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(IMAGE_PREFIX + filePrefix + 'confusion_matrix' + '.png')\n",
    "\n",
    "    for k in importantFeatures:\n",
    "        votes = importantFeatures[k]['votes']\n",
    "        coeffs = importantFeatures[k]['coefficients']\n",
    "        # Can't really think of a better way of capturing direction and magnitude as models could compete with each other so for now simple sum\n",
    "        sumCoeffs = sum(coeffs)\n",
    "        featureCoeffMapping = featureCoefficientMappings[k]\n",
    "        if votes > 0:\n",
    "            importantFeatureDf.loc[importantFeatureDf.shape[0]] = [k, votes, sumCoeffs, json.dumps(featureCoeffMapping)]\n",
    "\n",
    "    reportDf = reportDf.sort_values(sortBy, ascending=False)\n",
    "    importantFeatureDf = importantFeatureDf.sort_values(['votes','sum_coefficients'], ascending=False)\n",
    "    return reportDf, importantFeatureDf, classBalanceDf\n",
    "\n",
    "def printResults(name, filePrefix, reportDf, classBalanceDf, showTestScore=True, showTrainScore=True, showAvgFitTime=True, showClassMakeup=True, palette=MAIN_PALETTE_QUALITATIVE):\n",
    "    labels = {\n",
    "        'model': 'Model',\n",
    "        'train score': 'Training Score',\n",
    "        'test score': 'Testing Score',\n",
    "        'average fit time': 'Avg Fit Time',\n",
    "        'scoring_type': 'Grid Search CV Scoring Method',\n",
    "        'class_value': 'Class Value',\n",
    "        'class_percent': 'Class Percent'\n",
    "    }\n",
    "    \n",
    "    dataSetSuffix = f'{name}.'\n",
    "    spotsNeeded = 0;\n",
    "    if showTestScore:\n",
    "        spotsNeeded += 1\n",
    "\n",
    "    if showTrainScore:\n",
    "        spotsNeeded += 1\n",
    "\n",
    "    if showAvgFitTime:\n",
    "        spotsNeeded += 1\n",
    "\n",
    "    if showClassMakeup:\n",
    "        spotsNeeded += 1\n",
    "\n",
    "    orientationHorizontal = True\n",
    "    rowsNeeded = 1\n",
    "    colsNeeded = 1\n",
    "    rowIndex = 0\n",
    "    colIndex = 0\n",
    "    if orientationHorizontal:\n",
    "        colsNeeded = spotsNeeded\n",
    "    else:\n",
    "        rowsNeeded = spotsNeeded\n",
    "        \n",
    "    if spotsNeeded > 0:\n",
    "        xColumn = 'model'\n",
    "        xAxesLabel = labels[xColumn]\n",
    "        colorColumn = 'scoring_type'\n",
    "        dataLabelRotation = 90;\n",
    "        width = (640 / 100)  * colsNeeded\n",
    "        height = (480 / 100) * rowsNeeded\n",
    "        barWidthInches = 80 / 100\n",
    "    \n",
    "        plt.clf()\n",
    "        plt.figure()\n",
    "        \n",
    "        fig, ax = plt.subplots(rowsNeeded, colsNeeded, squeeze=False, figsize=(width, height))\n",
    "    \n",
    "        if showTestScore:\n",
    "            yColumn = 'test score'\n",
    "            yAxesLabel = labels[yColumn]\n",
    "            title = name + '- ' + labels[xColumn] + ' vs ' + labels[yColumn]\n",
    "            axSub = sns.barplot(ax=ax[rowIndex, colIndex], data=reportDf, x=xColumn, y=yColumn, hue=colorColumn, \n",
    "                             palette=palette, width=barWidthInches)\n",
    "            axSub.set_title(title)\n",
    "            axSub.set(xlabel=xAxesLabel, ylabel=yAxesLabel)\n",
    "            sns.move_legend(axSub, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "            for bars_group in axSub.containers: \n",
    "                axSub.bar_label(bars_group, padding=3, fontsize=8, rotation=dataLabelRotation, label_type='center')\n",
    "            if orientationHorizontal:\n",
    "                colIndex += 1\n",
    "            else:\n",
    "                rowIndex += 1\n",
    "    \n",
    "        if showTrainScore:\n",
    "            yColumn = 'train score'\n",
    "            yAxesLabel = labels[yColumn]\n",
    "            title = name + '- ' + labels[xColumn] + ' vs ' + labels[yColumn]\n",
    "            axSub = sns.barplot(ax=ax[rowIndex, colIndex], data=reportDf, x=xColumn, y=yColumn, hue=colorColumn, \n",
    "                             palette=palette, width=barWidthInches)\n",
    "            axSub.set_title(title)\n",
    "            axSub.set(xlabel=xAxesLabel, ylabel=yAxesLabel)\n",
    "            sns.move_legend(axSub, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "            for bars_group in axSub.containers: \n",
    "                axSub.bar_label(bars_group, padding=3, fontsize=8, rotation=dataLabelRotation, label_type='center')\n",
    "            if orientationHorizontal:\n",
    "                colIndex += 1\n",
    "            else:\n",
    "                rowIndex += 1\n",
    "    \n",
    "        if showAvgFitTime:\n",
    "            yColumn = 'average fit time'\n",
    "            yAxesLabel = labels[yColumn]\n",
    "            title = name + '- ' + labels[xColumn] + ' vs ' + labels[yColumn]\n",
    "            axSub = sns.barplot(ax=ax[rowIndex, colIndex], data=reportDf, x=xColumn, y=yColumn, hue=colorColumn, \n",
    "                             palette=palette, width=barWidthInches)\n",
    "            axSub.set_title(title)\n",
    "            axSub.set(xlabel=xAxesLabel, ylabel=yAxesLabel)\n",
    "            sns.move_legend(axSub, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "            for bars_group in axSub.containers: \n",
    "                axSub.bar_label(bars_group, padding=3, fontsize=8, rotation=dataLabelRotation, label_type='center')\n",
    "            if orientationHorizontal:\n",
    "                colIndex += 1\n",
    "            else:\n",
    "                rowIndex += 1\n",
    "    \n",
    "        if showClassMakeup:\n",
    "            xColumn = 'class_value'\n",
    "            yColumn = 'class_percent'\n",
    "            xAxesLabel = labels[xColumn]\n",
    "            yAxesLabel = labels[yColumn]\n",
    "            title = name + '- ' + labels[xColumn] + ' vs ' + labels[yColumn]\n",
    "            axSub = sns.barplot(ax=ax[rowIndex, colIndex], data=classBalanceDf, x=xColumn, y=yColumn, \n",
    "                             palette=palette, width=barWidthInches)\n",
    "            axSub.set_title(title)\n",
    "            axSub.set(xlabel=xAxesLabel, ylabel=yAxesLabel)\n",
    "            for bars_group in axSub.containers: \n",
    "                axSub.bar_label(bars_group, padding=3, fontsize=8, rotation=dataLabelRotation, label_type='center')\n",
    "            if orientationHorizontal:\n",
    "                colIndex += 1\n",
    "            else:\n",
    "                rowIndex += 1\n",
    "\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        plt.savefig(IMAGE_PREFIX + filePrefix + 'model_comparison_graphs.png')\n",
    "    \n",
    "    dataFrame2Html(reportDf,  filePrefix + 'model_comparison_report')\n",
    "\n",
    "def printModelAnalysis(reportDf, baselineScore, filePrefix, modelField = 'model', scoreField = 'test score', fitTimeField = 'average fit time', isBaseline=False, printPerformanceGraphs=False):\n",
    "    content = ''\n",
    "    content += '#### Confusion Matrix\\n'\n",
    "    img = addMarkdownImage('Confusion Matrix', filePrefix + 'confusion_matrix.png')\n",
    "    content += f'{img}\\n\\n'\n",
    "\n",
    "    content += '#### Performance Metrics (Tables)\\n'\n",
    "    content += pd.read_html(RESULT_FILE_PREFIX + filePrefix + 'model_comparison_report.dataFrame.html')[0].to_html(index=False, index_names=False, notebook=True)\n",
    "    content += '\\n\\n'\n",
    "    bestDf = reportDf.sort_values(scoreField, ascending=False)\n",
    "    bestModel = reportDf.iloc[0][modelField]\n",
    "    bestTestScore = bestDf.iloc[0][scoreField] * 100\n",
    "\n",
    "    if (printPerformanceGraphs) & (reportDf.shape[0] > 1):\n",
    "        content += '#### Performance Metrics (Visualized)\\n'\n",
    "        img = addMarkdownImage('Performance', filePrefix + 'model_comparison_graphs.png')\n",
    "        content += f'{img}\\n\\n'\n",
    "    \n",
    "    bestDf = reportDf.sort_values(scoreField, ascending=False)\n",
    "    bestModel = reportDf.iloc[0][modelField]\n",
    "    bestTestScore = bestDf.iloc[0][scoreField] * 100\n",
    "    \n",
    "    content += '#### Analysis\\n'\n",
    "    if reportDf.shape[0] == 1:\n",
    "        if isBaseline:\n",
    "            content += f'The {bestModel} has an accuracy test score of {bestTestScore}%\\n'\n",
    "        else:\n",
    "            content += f'The {bestModel} has an accuracy test score of {bestTestScore}% which is {\"better\" if bestTestScore > baselineScore else \"worse\"} than our baseline score of {baselineScore}%.\\n'\n",
    "    elif reportDf.shape[0] > 1:\n",
    "        worstModel = bestDf.iloc[bestDf.shape[0] - 1][modelField]\n",
    "        worstTestScore = bestDf.iloc[bestDf.shape[0] - 1][scoreField] * 100\n",
    "        bestDf = bestDf.sort_values(fitTimeField, ascending=True)\n",
    "        fastestModel = bestDf.iloc[0][modelField]\n",
    "        fastestTestScore = bestDf.iloc[0][scoreField] * 100\n",
    "        slowestModel = bestDf.iloc[bestDf.shape[0] - 1][modelField]\n",
    "        slowestTestScore = bestDf.iloc[bestDf.shape[0] - 1][scoreField] * 100\n",
    "        \n",
    "        content += f'- The best performing model is {bestModel} with a score of {bestTestScore}% which is {\"better\" if bestTestScore > baselineScore else \"worse\"} than our baseline score of {baselineModelTestScore}%.\\n'\n",
    "        content += f'- The worst performing model is {worstModel} with a score of {worstTestScore}% which is {\"better\" if worstTestScore > baselineScore else \"worse\"} than our baseline score of {baselineModelTestScore}%.\\n'\n",
    "        content += f'- The fastest performing model is {fastestModel} with a score of {fastestTestScore}% which is {\"better\" if fastestTestScore > baselineScore else \"worse\"} than our baseline score of {baselineModelTestScore}%.\\n'\n",
    "        content += f'- The slowest performing model is {slowestModel} with a score of {slowestTestScore}% which is {\"better\" if slowestTestScore > baselineScore else \"worse\"} than our baseline score of {baselineModelTestScore}%.\\n'\n",
    "        content += '\\n'\n",
    "\n",
    "    return content;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem1Content = '# Practical Application III: Comparing Classifiers\\n'\n",
    "problem1Content += '<b color=\"red\">NOTE: All images are clickable and higher resolution images will load in new browser window</b>\\n'\n",
    "problem1Content += '## Background\\n'\n",
    "problem1Content += 'We are trying to analyze the results of a Portugese Bank marketing campaign conducted over phone.\\n The goal of the campaign was to get a customer to sign up for a term deposit.\\n'\n",
    "problem1Content += 'The dataset collected is related to 17 campaigns that occurred between May 2008 and November 2010, corresponding to a total of 79354 contacts\\n\\n'\n",
    "problem1Content += 'We will follow the CRISP-DM process model consisting of Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, Deployment stages.\\n'\n",
    "writeString2File(problem1Content, RESULT_FILE_PREFIX + 'problem01.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(INPUT_FILE, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem2Content = ''\n",
    "problem2Content += '## CRISP DM: Data Understanding\\n'\n",
    "problem2Content += '### Data Shape\\n'\n",
    "problem2Content += 'The data has the following information\\n'\n",
    "buffer = io.StringIO()\n",
    "df.info(verbose=True, buf=buffer,show_counts=True)\n",
    "problem2Content += '```\\n'\n",
    "problem2Content += buffer.getvalue() + '\\n'\n",
    "problem2Content += '```\\n'\n",
    "writeString2File(problem2Content, RESULT_FILE_PREFIX + 'problem02.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "cellStartTime = timeit.default_timer()\n",
    "\n",
    "filePrefix = STEP03_PREFIX\n",
    "rawDf = df\n",
    "dataReportDf = addMetadataStatistics('raw', rawDf)\n",
    "display(dataReportDf)\n",
    "writeDataFrameDetails(data=rawDf, targetField=TARGET_FIELD, fileNameSuffix=filePrefix, titleSuffix=': Data Understanding')\n",
    "\n",
    "problem3Content = ''\n",
    "problem3Content += '### Features\\n'\n",
    "\n",
    "problem3Content += \"```\\n\"\n",
    "problem3Content += \"Input variables:\\n\"\n",
    "problem3Content += \"# bank client data:\\n\"\n",
    "problem3Content += \"1 - age (numeric)\\n\"\n",
    "problem3Content += \"2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\\n\"\n",
    "problem3Content += \"3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\\n\"\n",
    "problem3Content += \"4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\\n\"\n",
    "problem3Content += \"5 - default: has credit in default? (categorical: 'no','yes','unknown')\\n\"\n",
    "problem3Content += \"6 - housing: has housing loan? (categorical: 'no','yes','unknown')\\n\"\n",
    "problem3Content += \"7 - loan: has personal loan? (categorical: 'no','yes','unknown')\\n\"\n",
    "problem3Content += \"# related with the last contact of the current campaign:\\n\"\n",
    "problem3Content += \"8 - contact: contact communication type (categorical: 'cellular','telephone')\\n\"\n",
    "problem3Content += \"9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\\n\"\n",
    "problem3Content += \"10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\\n\"\n",
    "problem3Content += \"11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\\n\"\n",
    "problem3Content += \"# other attributes:\\n\"\n",
    "problem3Content += \"12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\\n\"\n",
    "problem3Content += \"13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\\n\"\n",
    "problem3Content += \"14 - previous: number of contacts performed before this campaign and for this client (numeric)\\n\"\n",
    "problem3Content += \"15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\\n\"\n",
    "problem3Content += \"# social and economic context attributes\\n\"\n",
    "problem3Content += \"16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\\n\"\n",
    "problem3Content += \"17 - cons.price.idx: consumer price index - monthly indicator (numeric)\\n\"\n",
    "problem3Content += \"18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\\n\"\n",
    "problem3Content += \"19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\\n\"\n",
    "problem3Content += \"20 - nr.employed: number of employees - quarterly indicator (numeric)\\n\"\n",
    "\n",
    "problem3Content += \"Output variable (desired target):\\n\"\n",
    "problem3Content += \"21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\\n\\n\"\n",
    "problem3Content += \"```\\n\"\n",
    "\n",
    "problem3Content += '#### Analysis\\n'\n",
    "problem3Content += 'Data has no missing values so we will examine content as based on the infromation it seems like empty values have been substituted\\n'\n",
    "problem3Content += '#### Data Distributions\\n'\n",
    "img = addMarkdownImage('Categorical Data Distribution', filePrefix + 'categorical.data.distribution.png')\n",
    "problem3Content += f'{img}\\n\\n'\n",
    "\n",
    "img = addMarkdownImage('Numerical Data Distribution', filePrefix + 'numeric.data.distribution.png')\n",
    "problem3Content += f'{img}\\n\\n'\n",
    "\n",
    "problem3Content += '#### Decisions\\n'\n",
    "problem3Content += '| Column | Notes | Decision |\\n'\n",
    "problem3Content += '| ------ | ----- | -------- |\\n'\n",
    "problem3Content += '| pdays | Majority of values are 999 | Drop column |\\n'\n",
    "problem3Content += '| job, marital, education, housing, loan | Unknown values account for small percentage of dataset | Drop rows |\\n'\n",
    "problem3Content += '| poutcome  | non-existent values account for large percentage and doesn\\'t add value  | Drop column |\\n'\n",
    "problem3Content += '| default  | most are no or unknown and doesn\\'t add value | Drop column |\\n'\n",
    "problem3Content += '| duration  | Per the information we should drop this column as it is not known at the time the prediction needs to be made. We can use it for benchmarking | Keep column but drop before finalizing final model |\\n'\n",
    "#problem3Content += '| duration  | Per the notes this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model | Drop column |\\n'\n",
    "problem3Content += '| nr.employed  | This has no bearing on whether a customer will sign up as it doesn\\'t represent information the customer would have for their decision | Drop column |\\n'\n",
    "\n",
    "RUNTIME_METRICS['Problem 3 Execution Time'] = timeit.default_timer() - cellStartTime\n",
    "writeString2File(problem3Content, RESULT_FILE_PREFIX + 'problem03.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "problem4Content = ''\n",
    "problem4Content += '## CRISP DM: Business Understanding\\n'\n",
    "problem4Content += '### Business Objective\\n'\n",
    "problem4Content += 'Our goal is to:\\n'\n",
    "problem4Content += '- First find a model that best predicts whether a user will sign up for a long term deposit after several contacts from a marketing campaign.\\n'\n",
    "problem4Content += '- Second use the model to explain what features contribute most significantly to the outcome of user signing up for a deposit.\\n'\n",
    "problem4Content += '- Lastly use this information to offer guidance to the bank on which customers to target based on features or approach so we can minimize resources, time and thus cost and maximize the desired result.\\n'\n",
    "writeString2File(problem4Content, RESULT_FILE_PREFIX + 'problem04.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "cellStartTime = timeit.default_timer()\n",
    "\n",
    "dataPreparationRequest = {\n",
    "    'excludeColumnsFromReport': ['y'],\n",
    "    'operations': [\n",
    "        {\n",
    "            'operation': 'dropDuplicates'\n",
    "        },\n",
    "         {\n",
    "                'operation': 'drop',\n",
    "                'config' : {\n",
    "                    'poutcome': {},\n",
    "                    'default': {},\n",
    "                    'pdays': {},\n",
    "                    'nr.employed': {}\n",
    "                }\n",
    "         },\n",
    "        {\n",
    "            'operation': 'queryFilter',\n",
    "            'config': {\n",
    "                'Drop rows with unknown': {\n",
    "                    'query': 'job != \"unknown\" & marital != \"unknown\" & education != \"unknown\" & housing != \"unknown\" & loan != \"unknown\"'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    'labels': {\n",
    "        'row_count': 'Row Count',\n",
    "        'na_value_count': 'Empty Value #',\n",
    "        'na_value_pct': 'Empty Value %',\n",
    "        'unq_value_count': 'Unique Value Counts',\n",
    "        'column': 'Feature'\n",
    "    }\n",
    "}\n",
    "filePrefix = STEP05_PREFIX\n",
    "preProcessedDf, dataReportDf = preProcessData(dataPreparationRequest, rawDf, dataReportDf)\n",
    "displayStats(request=dataPreparationRequest, dataReportDf=dataReportDf, prefix=filePrefix)\n",
    "writeDataFrameDetails(data=preProcessedDf, targetField=TARGET_FIELD, fileNameSuffix=filePrefix, titleSuffix=': Data Understanding (Preprocess)')\n",
    "\n",
    "numericFeatures = list(preProcessedDf.select_dtypes(include=[np.number]).columns.values)\n",
    "categoricalFeatures = list(preProcessedDf.select_dtypes(exclude=[np.number]).columns.values)\n",
    "print('Original Numeric Features: '+ str(numericFeatures))\n",
    "print('Original Categorical Features: '+ str(categoricalFeatures))\n",
    "\n",
    "numericFeaturesUsed = numericFeatures.copy()\n",
    "categoricalFeaturesUsed = categoricalFeatures.copy()\n",
    "for rf in IGNORE_FEATURES:\n",
    "    if rf in numericFeaturesUsed:\n",
    "        numericFeaturesUsed.remove(rf)\n",
    "    if rf in categoricalFeaturesUsed:\n",
    "        categoricalFeaturesUsed.remove(rf)\n",
    "\n",
    "# Do transform for categorical now because baking into pipeline means sometings columns in training set aren't in test and vice versa\n",
    "# Set target field to age since in this case we want to convert the y target field to numeric\n",
    "experimentDf = encodeAndAddCategoricalColumns(preProcessedDf, 'age', categoricalFeaturesUsed)\n",
    "finalNumericFeatures = list(experimentDf.select_dtypes(include=[np.number]).columns.values)\n",
    "experimentDf = experimentDf[finalNumericFeatures]\n",
    "experimentDf = experimentDf.rename(columns={\"y_yes\": \"y\"})\n",
    "print(experimentDf.info())\n",
    "\n",
    "problem5Content = ''\n",
    "problem5Content += '## CRISP DM: Data Preparations\\n'\n",
    "problem5Content += '### Feature Engineering Decisions\\n'\n",
    "problem5Content += 'We are asked to focus on just the \"bank client data\" features. In order to simplify later steps though we will also make some decisions around the \"other attributes\" and \"social and economic context attributes\" features to be efficent in our data preparation.\\n'\n",
    "problem5Content += '| Fields | Operation | Notes |\\n'\n",
    "problem5Content += '| ------ | ----- | -------- |\\n'\n",
    "operations = dataPreparationRequest['operations']\n",
    "for node in operations:\n",
    "    fields = []\n",
    "    operation = ''\n",
    "    notes = ''\n",
    "    operationName = node['operation']\n",
    "    if operationName == 'dropDuplicates':\n",
    "        operation = 'Drop duplicates'\n",
    "        problem5Content += f'| {fields} | {operation} | {notes} |\\n'\n",
    "    elif operationName == 'drop':\n",
    "        operation = 'Drop columns'\n",
    "        configNode = node['config']\n",
    "        fields = list(configNode.keys())\n",
    "        problem5Content += f'| {fields} | {operation} | {notes} |\\n'\n",
    "    elif operationName == 'queryFilter':\n",
    "        operation = 'Filter rows'\n",
    "        configNode = node['config']\n",
    "        for f in configNode:\n",
    "            queryNode = configNode[f]\n",
    "            desc = f\n",
    "            query = queryNode['query']\n",
    "            notes = f'Query: {query}'\n",
    "            problem5Content += f'| {fields} | {operation} | {notes} |\\n'\n",
    "\n",
    "\n",
    "\n",
    "fields = ['ALL CATEGORICAL']\n",
    "operation = 'One hot encode'\n",
    "notes = 'All categorical columns with < 255 unique values'\n",
    "problem5Content += f'| {fields} | {operation} | {notes} |\\n'\n",
    "\n",
    "fields = ['ALL CATEGORICAL']\n",
    "operation = 'Drop'\n",
    "notes = ''\n",
    "problem5Content += f'| {fields} | {operation} | {notes} |\\n'\n",
    "\n",
    "fields = ['y_yes']\n",
    "operation = 'rename'\n",
    "notes = 'rename to y'\n",
    "problem5Content +=f'| {fields} | {operation} | {notes} |\\n'\n",
    "\n",
    "\n",
    "problem5Content += '### Data Distributions\\n'\n",
    "img = addMarkdownImage('Categorical Data Distribution', filePrefix + 'categorical.data.distribution.png')\n",
    "problem5Content += f'{img}\\n\\n'\n",
    "\n",
    "img = addMarkdownImage('Numerical Data Distribution', filePrefix + 'numeric.data.distribution.png')\n",
    "problem5Content += f'{img}\\n\\n'\n",
    "\n",
    "problem5Content += '### Data Composition Change Tracking\\n'\n",
    "img = addMarkdownImage('Row Counts', filePrefix + 'row_count.png')\n",
    "img = addMarkdownImage('Unique Value Counts', filePrefix + 'unique_values.png')\n",
    "problem5Content += f'{img}\\n\\n'\n",
    "\n",
    "RUNTIME_METRICS['Problem 5 Execution Time'] = timeit.default_timer() - cellStartTime\n",
    "writeString2File(problem5Content, RESULT_FILE_PREFIX + 'problem05.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem6Content = ''\n",
    "problem6Content += '### Train/Test Split\\n'\n",
    "problem6Content += 'We will use the traditional split of 70% train / 30% split\\n'\n",
    "writeString2File(problem6Content, RESULT_FILE_PREFIX + 'problem06.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting this so information from previous sections does not bleed in\n",
    "name = None\n",
    "filePrefix = None\n",
    "reportDf = None\n",
    "importantFeatureDf = None\n",
    "classBalanceDf =  None\n",
    "\n",
    "# Begin\n",
    "name = 'Baseline'\n",
    "filePrefix=STEP07_PREFIX\n",
    "reportDf, importantFeatureDf, classBalanceDf = runAnalysis(name=name, \n",
    "                                                           filePrefix=filePrefix, \n",
    "                                                           data=experimentDf, \n",
    "                                                           targetField=TARGET_FIELD, \n",
    "                                                           models2Try=BASELINE_MODEL_2_TRY,\n",
    "                                                           directModel=True,\n",
    "                                                           scoringTypes=DEFAULT_GRID_SEARCH_SCORING_TYPES)\n",
    "printResults(name=name, filePrefix=filePrefix, reportDf=reportDf, classBalanceDf=classBalanceDf, \n",
    "             showTestScore=False, showTrainScore=False, showAvgFitTime=False, showClassMakeup=False)\n",
    "dataFrame2Html(importantFeatureDf,  filePrefix + 'important_features')\n",
    "writeDataFrame2Excel(reportDf, filePrefix)\n",
    "writeDataFrame2Excel(importantFeatureDf, filePrefix + 'features')\n",
    "\n",
    "# Store baseline score for use later\n",
    "baselineModelTestScore = reportDf.iloc[0]['test score'] * 100\n",
    "\n",
    "problem7Content = ''\n",
    "problem7Content += '## CRISP DM: Modeling\\n'\n",
    "problem7Content += '- We will use the accuracy of the test score to evaluate the models against each other and select best model during Grid Search.\\n'\n",
    "problem7Content += '- However if the bank had an opinon for example one of the ones below we would adjust the scoring type.\\n'\n",
    "problem7Content += '  - Recall: If we wanted to make sure we didn\\'t miss any customers that may sign up we would optimize for recall.\\n'\n",
    "problem7Content += '  - Precision: If we wanted to make sure we only spend time contacting customers that are likely sign up we would optimize for precision.\\n'\n",
    "problem7Content += '### Baseline Model\\n'\n",
    "problem7Content += printModelAnalysis(reportDf=reportDf, filePrefix=filePrefix, baselineScore=baselineModelTestScore, isBaseline=True)\n",
    "writeString2File(problem7Content, RESULT_FILE_PREFIX + 'problem07.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "cellStartTime = timeit.default_timer()\n",
    "\n",
    "# Setting this so information from previous sections does not bleed in\n",
    "name = None\n",
    "filePrefix = None\n",
    "reportDf = None\n",
    "importantFeatureDf = None\n",
    "classBalanceDf =  None\n",
    "\n",
    "# Begin\n",
    "name = 'Simple Model - Logistic Regression'\n",
    "filePrefix=STEP08_PREFIX\n",
    "reportDf, importantFeatureDf, classBalanceDf = runAnalysis(name=name, \n",
    "                                                           filePrefix=filePrefix, \n",
    "                                                           data=experimentDf, \n",
    "                                                           targetField=TARGET_FIELD, \n",
    "                                                           models2Try=SIMPLE_MODEL_2_TRY,\n",
    "                                                           directModel=True,\n",
    "                                                           scoringTypes=DEFAULT_GRID_SEARCH_SCORING_TYPES)\n",
    "printResults(name=name, filePrefix=filePrefix, reportDf=reportDf, classBalanceDf=classBalanceDf, \n",
    "             showTestScore=False, showTrainScore=False, showAvgFitTime=False, showClassMakeup=False)\n",
    "dataFrame2Html(importantFeatureDf,  filePrefix + 'important_features')\n",
    "writeDataFrame2Excel(reportDf, filePrefix)\n",
    "writeDataFrame2Excel(importantFeatureDf, filePrefix + 'features')\n",
    "\n",
    "problem8Content = ''\n",
    "problem8Content += '### A Simple Model (Logistic Regression)\\n'\n",
    "problem8Content += 'We are training a Logistic Regression model with default values\\n'\n",
    "\n",
    "problem9Content = ''\n",
    "problem9Content += printModelAnalysis(reportDf=reportDf, filePrefix=filePrefix, baselineScore=baselineModelTestScore)\n",
    "\n",
    "RUNTIME_METRICS['Problem 9 Execution Time'] = timeit.default_timer() - cellStartTime\n",
    "writeString2File(problem9Content, RESULT_FILE_PREFIX + 'problem09.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "cellStartTime = timeit.default_timer()\n",
    "\n",
    "# Setting this so information from previous sections does not bleed in\n",
    "name = None\n",
    "filePrefix = None\n",
    "reportDf = None\n",
    "importantFeatureDf = None\n",
    "classBalanceDf =  None\n",
    "\n",
    "# Begin\n",
    "name = 'Model Comparisons'\n",
    "filePrefix=STEP10_PREFIX\n",
    "reportDf, importantFeatureDf, classBalanceDf = runAnalysis(name=name, \n",
    "                                                           filePrefix=filePrefix, \n",
    "                                                           data=experimentDf, \n",
    "                                                           targetField=TARGET_FIELD, \n",
    "                                                           models2Try=DEFAULT_MODELS_2_TRY,\n",
    "                                                           directModel=True,\n",
    "                                                           scoringTypes=DEFAULT_GRID_SEARCH_SCORING_TYPES)\n",
    "printResults(name=name, filePrefix=filePrefix, reportDf=reportDf, classBalanceDf=classBalanceDf, \n",
    "             showClassMakeup=False)\n",
    "dataFrame2Html(importantFeatureDf,  filePrefix + 'important_features')\n",
    "writeDataFrame2Excel(reportDf, filePrefix)\n",
    "writeDataFrame2Excel(importantFeatureDf, filePrefix + 'features')\n",
    "\n",
    "problem10Content = ''\n",
    "problem10Content += '### Multiple Default Model Comparisons\\n'\n",
    "problem10Content += 'Comparing mutlipel models using default hyperparameters/settings we find.\\n'\n",
    "problem10Content += printModelAnalysis(reportDf=reportDf, filePrefix=filePrefix, baselineScore=baselineModelTestScore, printPerformanceGraphs=True)\n",
    "\n",
    "RUNTIME_METRICS['Problem 10 Execution Time'] = timeit.default_timer() - cellStartTime\n",
    "writeString2File(problem10Content, RESULT_FILE_PREFIX + 'problem10.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "cellStartTime = timeit.default_timer()\n",
    "\n",
    "# Setting this so information from previous sections does not bleed in\n",
    "name = None\n",
    "filePrefix = None\n",
    "reportDf = None\n",
    "importantFeatureDf = None\n",
    "classBalanceDf =  None\n",
    "\n",
    "# Begin\n",
    "def runExperiment(name, filePrefix, data):\n",
    "    reportDf, importantFeatureDf, classBalanceDf = runAnalysis(name=name, \n",
    "                                                           filePrefix=filePrefix, \n",
    "                                                           data=data, \n",
    "                                                           targetField=TARGET_FIELD, \n",
    "                                                           models2Try=GRID_SEARCH_MODELS_2_TRY,\n",
    "                                                           scoringTypes=DEFAULT_GRID_SEARCH_SCORING_TYPES)\n",
    "    printResults(name=name, filePrefix=filePrefix, reportDf=reportDf, classBalanceDf=classBalanceDf)\n",
    "    dataFrame2Html(importantFeatureDf,  filePrefix + 'important_features',)\n",
    "    writeDataFrame2Excel(reportDf, filePrefix)\n",
    "    writeDataFrame2Excel(importantFeatureDf, filePrefix + 'features')\n",
    "\n",
    "    content = ''\n",
    "    content += printModelAnalysis(reportDf=reportDf, filePrefix=filePrefix, baselineScore=baselineModelTestScore, printPerformanceGraphs=True)\n",
    "\n",
    "    return content, reportDf, importantFeatureDf, classBalanceDf\n",
    "\n",
    "\n",
    "name = 'Improving Model - Grid Search'\n",
    "problem11Content = ''\n",
    "currentDataFrameColumns = list(experimentDf.columns.values)\n",
    "print(currentDataFrameColumns)\n",
    "for ek in EXPERIMENTS:\n",
    "    experiment = EXPERIMENTS[ek]\n",
    "    filePrefix = STEP11_PREFIX + ek + '.'\n",
    "    experiment['filePrefix'] = filePrefix\n",
    "    experimentName = experiment['name']\n",
    "    experimentDescription = experiment['description']\n",
    "    experimentFeatures = experiment['features']\n",
    "    finalFeatures = []\n",
    "    for dfk in currentDataFrameColumns:\n",
    "        for fk in experimentFeatures:\n",
    "            if dfk.startswith(fk):\n",
    "                finalFeatures.append(dfk)\n",
    "    experiment['encodedFeatures'] = finalFeatures\n",
    "    data = experimentDf[finalFeatures]\n",
    "    problem11Content += f'### Grid Search - {experimentName}\\n'\n",
    "    problem11Content += f'{experimentDescription}\\n'\n",
    "    content, reportDf, importantFeatureDf, classBalanceDf = runExperiment(name=name, filePrefix=filePrefix, data=data)\n",
    "    problem11Content += content\n",
    "    experiment['reportDf'] = reportDf\n",
    "    experiment['importantFeatureDf'] = importantFeatureDf\n",
    "    experiment['classBalanceDf'] = classBalanceDf\n",
    "\n",
    "RUNTIME_METRICS['Problem 11 Execution Time'] = timeit.default_timer() - cellStartTime\n",
    "writeString2File(problem11Content, RESULT_FILE_PREFIX + 'problem11.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 12: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "cellStartTime = timeit.default_timer()\n",
    "\n",
    "# Setting this so information from previous sections does not bleed in\n",
    "name = None\n",
    "filePrefix = None\n",
    "reportDf = None\n",
    "importantFeatureDf = None\n",
    "classBalanceDf =  None\n",
    "\n",
    "# Begin\n",
    "def runEvaluation(filePrefix, key, experiment):\n",
    "    # Gather data and previous results\n",
    "    targetField = TARGET_FIELD\n",
    "    experimentName = experiment['name']\n",
    "    experimentFilePrefix = experiment['filePrefix']\n",
    "    experimentDescription = experiment['description']\n",
    "    experimentFeatures = experiment['encodedFeatures']\n",
    "    experimentRawFeatures = experiment['features']\n",
    "    printDistributionGraphs = False\n",
    "    if 'printDistributionGraphs' in experiment:\n",
    "        printDistributionGraphs = experiment['printDistributionGraphs']\n",
    "\n",
    "    printDecisionTree = True\n",
    "    if 'printDecisionTree' in experiment:\n",
    "        printDecisionTree = experiment['printDecisionTree']\n",
    "    data = experimentDf[experimentFeatures]\n",
    "    reportDf = experiment['reportDf']\n",
    "    importantFeatureDf = experiment['importantFeatureDf']\n",
    "\n",
    "    content = ''\n",
    "    content += f'### {experimentName}\\n'\n",
    "\n",
    "    encodedImportantFeatures = list(importantFeatureDf['feature'].values)\n",
    "    # Print important feeatures\n",
    "    if importantFeatureDf.shape[0] > 0:\n",
    "        features = encodedImportantFeatures\n",
    "        # Determine important fields\n",
    "        finalImportantFieldsContent = []\n",
    "        for f in features:\n",
    "            column = f.split('_')[0]\n",
    "            if column not in finalImportantFieldsContent:\n",
    "                finalImportantFieldsContent.append(column)\n",
    "        content += '#### Feature Importance\\n'\n",
    "        content += f'\\nImportant features using voting approach:\\n\\n{finalImportantFieldsContent}\\n\\n'\n",
    "        content += f'The specific values of these important features are:\\n'\n",
    "        \n",
    "        content +=  pd.read_html(RESULT_FILE_PREFIX + STEP11_PREFIX + f'{key}.important_features.dataFrame.html')[0].to_html(index=False, index_names=False, notebook=True)\n",
    "        content += '\\n\\n'\n",
    "        \n",
    "\n",
    "    # Show distribution graphs\n",
    "    if printDistributionGraphs:\n",
    "        # Special treatment for visualization\n",
    "        ageField = 'age'\n",
    "\n",
    "        # Some of these columns won't be in the pre-processed set so filter out\n",
    "        preProcessedColumns = preProcessedDf.columns.values\n",
    "        analyzeColumns = []\n",
    "        for f in experimentRawFeatures:\n",
    "            if f in preProcessedColumns:\n",
    "                analyzeColumns.append(f)\n",
    "                \n",
    "        # Get complete list of columns to analyze + target field\n",
    "        if targetField not in analyzeColumns:\n",
    "            analyzeColumns.append(targetField)\n",
    "        if ageField not in analyzeColumns:\n",
    "            analyzeColumns.append(ageField)\n",
    "        \n",
    "        analysisDf = preProcessedDf[analyzeColumns]\n",
    "    \n",
    "        # Numeric fields we want to render differently\n",
    "        numCols = list(analysisDf.select_dtypes(include=[np.number]).columns.values)\n",
    "        if ageField in numCols:\n",
    "            numCols.remove(ageField)\n",
    "        if targetField not in numCols:\n",
    "            numCols.append(targetField)\n",
    "    \n",
    "        # Categorical we want to see possibility of success\n",
    "        catCols = list(analysisDf.select_dtypes(exclude=[np.number]).columns.values)\n",
    "        if ageField in catCols:\n",
    "            catCols.remove(ageField)\n",
    "        if targetField not in catCols:\n",
    "            catCols.append(targetField)\n",
    "\n",
    "    \n",
    "        # Finaly generate graphs\n",
    "        generatePercentCompositionBarReport4Columns({}, df2Use=analysisDf, targetField=targetField, columns=catCols, \n",
    "                                                    fileSuffix=filePrefix + 'important.categorical.data.distribution', \n",
    "                                                    baseWidth=1800, baseHeight=1600, \n",
    "                                                    highlightColumns=finalImportantFieldsContent)\n",
    "        # Age we want to render by itself for visibility\n",
    "        generatePercentCompositionBarReport4Columns({}, df2Use=analysisDf, targetField=targetField, columns=[ageField], \n",
    "                                                    fileSuffix=filePrefix + 'important.age.data.distribution', \n",
    "                                                    baseWidth=1800, baseHeight=1600, \n",
    "                                                    highlightColumns=finalImportantFieldsContent)\n",
    "    \n",
    "    \n",
    "    \n",
    "        writeDataFrameDetails(data=analysisDf[numCols], targetField=targetField, \n",
    "                              fileNameSuffix=filePrefix + 'important', titleSuffix=': Final Report',\n",
    "                              highlightColumns=finalImportantFieldsContent)\n",
    "        content += '#### Analysis\\n'\n",
    "        content += '#### Data Distributions\\n'\n",
    "        content += '**NOTE:** Important features highlighted using different palette\\n'\n",
    "        img = addMarkdownImage('Important Categorical Data Distribution', filePrefix + 'important.categorical.data.distribution.png')\n",
    "        content += f'{img}\\n'\n",
    "        img = addMarkdownImage('Important Age Data Distribution', filePrefix + 'important.age.data.distribution.png')\n",
    "        content += f'{img}\\n\\n'\n",
    "        img = addMarkdownImage('Numerical Data Distribution', filePrefix + 'important.numeric.data.distribution.png')\n",
    "        content += f'{img}\\n\\n'\n",
    "    \n",
    "    # Show decision tree\n",
    "    if printDecisionTree:\n",
    "        decisionTreeBestParams = reportDf.loc[reportDf['model'] == 'Decision Tree'].iloc[0]['best_params']\n",
    "        params = json.loads(decisionTreeBestParams)\n",
    "        maxDepth = params['max_depth']\n",
    "    \n",
    "        # Train the model\n",
    "        targetField = TARGET_FIELD\n",
    "        featureFields = list(data.columns.values)\n",
    "        featureFields.remove(targetField);\n",
    "        X = experimentDf[featureFields]\n",
    "        y = experimentDf[[targetField]]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = DecisionTreeClassifier(random_state=42, criterion=params['criterion'], max_depth=maxDepth)\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "        #display(model)\n",
    "        # https://mljar.com/blog/visualize-decision-tree/\n",
    "        \n",
    "        width = 12 * maxDepth\n",
    "        height = 0.5 * (2 ** maxDepth)    \n",
    "        plt.clf()\n",
    "        fig, ax = plt.subplots(figsize = (width, height))\n",
    "        featureNames = list(X_train.columns)\n",
    "        tree_plot = plot_tree(model, \n",
    "                              ax = ax,\n",
    "                              feature_names=featureNames, \n",
    "                              class_names=True,\n",
    "                              filled=True,  \n",
    "                              fontsize=8);\n",
    "        \n",
    "        fileSuffix = filePrefix + '.decision_tree_final.png'\n",
    "        plt.savefig(IMAGE_PREFIX + fileSuffix)\n",
    "        \n",
    "        \n",
    "        img = addMarkdownImage(name='Decision Tree', path=fileSuffix)\n",
    "        content += '#### Decision Tree\\n'\n",
    "        content += 'The descision tree is more easily interpretable/explainable to help with the understanding how the model works and can help the bank make decisions about optimizing the campaign.\\n'\n",
    "        content += f'{img}\\n'\n",
    "\n",
    "    return content\n",
    "\n",
    "filePrefix = STEP12_PREFIX\n",
    "problem12Content = ''\n",
    "problem12Content += '## CRISP DM: Evaluation\\n'\n",
    "problem12Content += 'Using a \"voting\" approach where each time a feature is deemed important by a model it increments the vote. Coefficents are including to evaluate direction and magnitude as well.\\n'\n",
    "for ek in EXPERIMENTS:\n",
    "    experiment = EXPERIMENTS[ek]\n",
    "    problem12Content += runEvaluation(filePrefix, ek, experiment)\n",
    "\n",
    "RUNTIME_METRICS['Problem 12 Execution Time'] = timeit.default_timer() - cellStartTime\n",
    "writeString2File(problem12Content, RESULT_FILE_PREFIX + 'problem12.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noteBookContent = '## Research Code\\n'\n",
    "noteBookContent += '**Code:** [Data Analysis Workbook](./prompt_III.out.ipynb)\\n\\n'\n",
    "noteBookContent += '**NOTE:** *The processing of the juypter notebook take a long time and often disconnects from the session. In order to run it without monitoring it all the time use the wokraround below from command line.*\\n'\n",
    "noteBookContent += '```\\n'\n",
    "noteBookContent += 'jupyter nbconvert --to notebook --execute {input_notebook} --output={output_notebook} --ExecutePreprocessor.timeout=-1\\n'\n",
    "noteBookContent += '```\\n'\n",
    "noteBookContent += '<sub>Source: [screen-and-jupyter-a-way-to-run-long-notebooks-headles](https://www.maksimeren.com/post/screen-and-jupyter-a-way-to-run-long-notebooks-headless/)</sub>\\n\\n'\n",
    "noteBookContent += 'Jump to the good stuff: [Summary, Observations and Guidance](#next-steps-summary-observations-and-guidance)\\n'\n",
    "\n",
    "readMeContent = ''\n",
    "readMeContent += readFile( RESULT_FILE_PREFIX + 'problem01.md')\n",
    "readMeContent += noteBookContent\n",
    "readMeContent += readFile( RESULT_FILE_PREFIX + 'problem02.md')\n",
    "readMeContent += readFile( RESULT_FILE_PREFIX + 'problem03.md')\n",
    "readMeContent += readFile( RESULT_FILE_PREFIX + 'problem04.md')\n",
    "readMeContent += readFile( RESULT_FILE_PREFIX + 'problem05.md')\n",
    "readMeContent += readFile( RESULT_FILE_PREFIX + 'problem06.md')\n",
    "readMeContent += readFile( RESULT_FILE_PREFIX + 'problem07.md')\n",
    "#readMeContent += readFile( RESULT_FILE_PREFIX + 'problem08.md')\n",
    "readMeContent += readFile( RESULT_FILE_PREFIX + 'problem09.md')\n",
    "readMeContent += readFile( RESULT_FILE_PREFIX + 'problem10.md')\n",
    "readMeContent += readFile( RESULT_FILE_PREFIX + 'problem11.md')\n",
    "readMeContent += readFile( RESULT_FILE_PREFIX + 'problem12.md')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "reportingContent = ''\n",
    "reportingContent += '## Next Steps: Summary, Observations and Guidance\\n'\n",
    "\n",
    "featureReporting = {\n",
    "    'month': {\n",
    "        'observation': 'Certain months show better success than others e.g. March and months towards end of year.',\n",
    "        'guidance': 'Maybe ramp down the calls to save on cost during the down months or increase calls during peak months.'\n",
    "    },\n",
    "    'age': {\n",
    "        'observation': 'Ages above 60 and below have better success however have smaller numbers. There is a bracket between 30-35 with more success.',\n",
    "        'guidance': 'Target customers in the brackets 30-35 and above 60.'\n",
    "    },\n",
    "    'job': {\n",
    "        'observation': 'Middle class, students and retired folks more success.',\n",
    "        'guidance': 'Target customers in the middle class jobs (particularly admin and technicians), retired people and students.'\n",
    "    },\n",
    "    'duration': {\n",
    "        'observation': 'Durations of around 300 seconds appear to be more successful. Though this may just be a function of customers who were going to accept and having longer discussions.',\n",
    "        'guidance': 'Plan on your agents spending at least 300 seconds to talk to customers. This is more of a staffing suggestion based on how many callouts.'\n",
    "    },\n",
    "    'campaign': {\n",
    "        'observation': 'Seems like we have some success reaching out between 1-4 times.',\n",
    "        'guidance': 'Don\\'t bother calling customers more than 4 times.'\n",
    "    },\n",
    "    'cons.conf.idx': {\n",
    "        'observation': 'These the bank has no control over this but it affects success.',\n",
    "        'guidance': 'Adjust agent resources up/down based on this indicator.'\n",
    "    },\n",
    "    'cons.price.idx': {\n",
    "        'observation': 'These the bank has no control over this but it affects success.',\n",
    "        'guidance': 'Adjust agent resources up/down based on this indicator.'\n",
    "    },\n",
    "    'emp.var.rate': {\n",
    "        'observation': 'These the bank has no control over this but it affects success.',\n",
    "        'guidance': 'Adjust agent resources up/down based on this indicator.'\n",
    "    },\n",
    "    'euribor3m': {\n",
    "        'observation': 'These the bank has no control over this but it affects success.',\n",
    "        'guidance': 'Adjust agent resources up/down based on this indicator.'\n",
    "    }\n",
    "}\n",
    "\n",
    "TICK = '&#10003;'\n",
    "CROSS = '&#10007;'\n",
    "\n",
    "# Model Summary\n",
    "baseLineReportDf = pd.read_excel(RESULT_FILE_PREFIX + STEP07_PREFIX + f'dataFrame.xlsx')\n",
    "baseLineScore = baseLineReportDf.iloc[0]['test score'] * 100\n",
    "modelContent = '#### Model Observations and Guidance\\n'\n",
    "modelContent += f'- Our Baseline score: {baseLineScore:.5f}%\\n'\n",
    "modelContent += f'- Model Analysis:\\n'\n",
    "modelContent += '    - Observation: SVC always performs significantly slower that the other models.\\n'\n",
    "modelContent += '    - Guidance: For very large sets where compute resources are an issue during training we may stay away from SVM model.\\n\\n'\n",
    "\n",
    "modelContent += '#### Experiment - Best Model and Hyperparameters\\n'\n",
    "modelContent += '<table>\\n'\n",
    "modelContent +='<tr><th>Experiment</th><th>Best Model</th><th>Best Parameters</th><th>Accuracy Test Score</th><th>Better Than Baseline</th><th>Important Features</th></tr>\\n'\n",
    "\n",
    "# Feature Summary\n",
    "featureContent = '#### Experiment - Best Model Identified Important Features\\n'\n",
    "featureContent += '<table>\\n'\n",
    "featureContent +='<tr><th>Experiment</th><th>Feature</th><th>Value</th><th>Direction</th><th>Magnitude</th></tr>\\n'\n",
    "\n",
    "\n",
    "for ek in EXPERIMENTS:\n",
    "    experiment = EXPERIMENTS[ek]\n",
    "    experimentName = experiment['name']\n",
    "    reportDf = pd.read_excel(RESULT_FILE_PREFIX + STEP11_PREFIX + f'{ek}.dataFrame.xlsx')\n",
    "    importantFeatureDf = pd.read_excel(RESULT_FILE_PREFIX + STEP11_PREFIX + f'{ek}.features.dataFrame.xlsx')\n",
    "    finalModelDecisionDf = reportDf.sort_values('test score', ascending=False)\n",
    "    bestModel = finalModelDecisionDf.iloc[0]['model']\n",
    "    bestParams = finalModelDecisionDf.iloc[0]['best_params']\n",
    "    bestScore = finalModelDecisionDf.iloc[0]['test score'] * 100\n",
    "\n",
    "    featuresEncoded = list(importantFeatureDf['feature'].values)\n",
    "    # Determine important fields\n",
    "    importanceIndicator = {}\n",
    "    better = TICK if bestScore > baseLineScore else CROSS\n",
    "    modelContent += f'<tr><td>{experimentName}</td><td>{bestModel}</th><td>{bestParams}</td><td>{bestScore:.5}%</td><td>{better}</td><td>{featuresEncoded}</td></tr>\\n'\n",
    "\n",
    "    experimentSpan = importantFeatureDf.shape[0]\n",
    "    for index, row in importantFeatureDf.iterrows():\n",
    "        feature = row['feature']\n",
    "        coeff = row['sum_coefficients']\n",
    "        parts = feature.split('_')\n",
    "        column = parts[0]\n",
    "        if(len(parts) > 1):\n",
    "            featureValue = feature[len(column) + 1:]\n",
    "            if column not in importanceIndicator:\n",
    "                importanceIndicator[column] = {}\n",
    "            columnNode = importanceIndicator[column]\n",
    "            if featureValue not in columnNode:\n",
    "                columnNode[featureValue] = {}\n",
    "            featureNode = columnNode[featureValue]\n",
    "            featureNode['coeff'] = coeff\n",
    "        else:\n",
    "            featureValue = '{numeric}'\n",
    "            if column not in importanceIndicator:\n",
    "                importanceIndicator[column] = {}\n",
    "            columnNode = importanceIndicator[column]\n",
    "            if featureValue not in columnNode:\n",
    "                columnNode[featureValue] = {}\n",
    "            featureNode = columnNode[featureValue]\n",
    "            featureNode['coeff'] = coeff\n",
    "\n",
    "    experimentRow = 0\n",
    "    for ck in importanceIndicator:\n",
    "        columnNode = importanceIndicator[ck]\n",
    "        columnSpan = len(columnNode)\n",
    "        columnRow = 0\n",
    "        for fk in columnNode:\n",
    "            featureNode = columnNode[fk]\n",
    "            coeff = featureNode['coeff']\n",
    "            if coeff > 0:\n",
    "                indicator = '&#8679;'\n",
    "            elif coeff < 0:\n",
    "                indicator = '&#8681;'\n",
    "            else:\n",
    "                indicator = '&#8660;'\n",
    "            if experimentRow == 0:\n",
    "                featureContent += f'<tr><td rowspan=\"{experimentSpan}\">{experimentName}</td><td rowspan=\"{columnSpan}\">{ck}</td><td>{fk}</td><td>{indicator}</td><td>{coeff}</td></tr>\\n'\n",
    "            elif columnRow == 0:\n",
    "                featureContent += f'<tr><td rowspan=\"{columnSpan}\">{ck}</td><td>{fk}</td><td>{indicator}</td><td>{coeff}</td></tr>\\n'\n",
    "            else:\n",
    "                featureContent += f'<tr><td>{fk}</td><td>{indicator}</td><td>{coeff}</td></tr>\\n'\n",
    "            columnRow += 1\n",
    "            experimentRow += 1\n",
    "    \n",
    "\n",
    "modelContent += '</table>\\n\\n'\n",
    "featureContent += '</table>\\n\\n'\n",
    "\n",
    "summaryContent = ''\n",
    "summaryContent = '### Guidance\\n'\n",
    "summaryContent += '- Even though the models identify important features we select some additional ones based on the data we have that show higher chance of success.\\n\\n'\n",
    "summaryContent += '<table>\\n\\n'\n",
    "summaryContent += '<tr><th>Feature</th><th>Observation</th><th>Guidance</th></tr>\\n'\n",
    "for f in featureReporting:\n",
    "    currFeature = f\n",
    "    node = featureReporting[f]\n",
    "    source = ''\n",
    "    if currFeature in FEATURES_BANK_CLIENT_DATA:\n",
    "        source = 'Bank Client Data'\n",
    "    if currFeature in FEATURES_OTHER:\n",
    "        source = 'Other'\n",
    "    if currFeature in FEATURES_SOCIAL_ECONOMIC:\n",
    "        source = 'Social and Economic Indicators'\n",
    "    observation = node['observation']\n",
    "    guidance = node['guidance']\n",
    "    summaryContent += f'<tr><td>{currFeature}</td><td>{observation}</td><td>{guidance}</td></tr>\\n'\n",
    "summaryContent += '</table>\\n\\n'\n",
    "\n",
    "reportingContent += '### Summary\\n'\n",
    "reportingContent += modelContent\n",
    "reportingContent += featureContent\n",
    "reportingContent += summaryContent\n",
    "\n",
    "\n",
    "# Add runtime metrics\n",
    "RUNTIME_METRICS['start_time'] = f'{BEGIN_RUN_DATETIME}'\n",
    "RUNTIME_METRICS['end_time'] = f'{datetime.datetime.now()}'\n",
    "RUNTIME_METRICS['total_execution_time'] = timeit.default_timer() - EXECUTION_START_TIME\n",
    "jsonRuntimeMetrics = json.dumps(RUNTIME_METRICS, indent=2)\n",
    "\n",
    "reportingContent += f'##### Runtime Metrics:\\n'\n",
    "reportingContent += '```\\n'\n",
    "reportingContent += f'{jsonRuntimeMetrics}\\n'\n",
    "reportingContent += '```\\n'\n",
    "\n",
    "readMeContent += reportingContent\n",
    "\n",
    "#display(Markdown(readMeContent))\n",
    "writeString2File(readMeContent, README_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
