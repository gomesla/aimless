{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e803907e-0b0c-4f6a-944d-e721c4059267",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626eda93-e8c5-48b4-a1f6-984bc0bc6fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# NOTE: This will fail for large dataset processing or complex model evaluation\n",
    "# Use the command below to run it in the background \n",
    "##############################\n",
    "# Source: https://www.maksimeren.com/post/screen-and-jupyter-a-way-to-run-long-notebooks-headless/\n",
    "# jupyter nbconvert --to notebook --execute capstone.template.ipynb --output=capstone.out.ipynb --ExecutePreprocessor.timeout=-1\n",
    "\n",
    "##############################\n",
    "# Library Imports\n",
    "##############################\n",
    "import copy\n",
    "import json\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import io\n",
    "from datetime import datetime\n",
    "from random import randint\n",
    "import timeit\n",
    "import datetime\n",
    "\n",
    "from IPython.core.getipython import get_ipython\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Frameworks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "\n",
    "\n",
    "# Plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn import metrics\n",
    "from sklearn import set_config\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score, mean_squared_error, multilabel_confusion_matrix, ConfusionMatrixDisplay, confusion_matrix, accuracy_score, recall_score, precision_score, precision_recall_curve, roc_curve, RocCurveDisplay, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.compose import make_column_transformer, make_column_selector, TransformedTargetRegressor, ColumnTransformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "##############################\n",
    "# Needed methods to bootstrap\n",
    "##############################\n",
    "def readFile(path, notFoundException=True):\n",
    "    data = '';\n",
    "    if os.path.exists(path):\n",
    "        with open(path) as f: \n",
    "            data = f.read()\n",
    "    elif notFoundException:\n",
    "        raise Exception(f'{path} does not exist')\n",
    "    return data\n",
    "\n",
    "def readJson(path):\n",
    "    data = readFile(path)\n",
    "    return json.loads(data)\n",
    "\n",
    "def writeString2File(string2Write, path, print2Screen = False):\n",
    "    if print2Screen:\n",
    "        print(string2Write)\n",
    "    with open(path, \"w\") as text_file:\n",
    "        text_file.write(str(string2Write))\n",
    "##############################\n",
    "# Configuration + Flow control\n",
    "##############################\n",
    "GRID_SEARCH_JOBS = 4\n",
    "BEGIN_RUN_DATETIME = datetime.datetime.now()\n",
    "SETTINGS = readJson('./settings.json')\n",
    "EXECUTION_MODE = SETTINGS['mode']\n",
    "DEV_MODE = \"development\" == EXECUTION_MODE\n",
    "print(f'Execution mode: {EXECUTION_MODE}')\n",
    "EXECUTION_START_TIME = timeit.default_timer()\n",
    "RUNTIME_METRICS = {}\n",
    "\n",
    "##############################\n",
    "# Runtime Settings\n",
    "##############################\n",
    "set_config(display=\"diagram\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "##############################\n",
    "# Constants\n",
    "##############################\n",
    "# https://seaborn.pydata.org/tutorial/color_palettes.html#sequential-color-palettes\n",
    "MAIN_PALETTE_QUALITATIVE = 'pastel'\n",
    "HIGHLIGHT_PALETTE_QUALITATIVE = 'Pastel2'\n",
    "MAIN_PALETTE_SEQUENTIAL = 'crest'\n",
    "IMAGE_DIR_SUFFIX = ''\n",
    "INPUT_FILE = './data/all_tickets_processed_improved_v3.csv'\n",
    "RESULT_DIR = f'./analysis_results'    \n",
    "README_FILE = f'./README.md'\n",
    "TARGET_FIELD = 'target'\n",
    "DOCUMENT_FIELD = 'Original'\n",
    "STEMMED_FIELD = 'Stemmed';\n",
    "LEMMATIZED_FIELD = 'Lemmatized';\n",
    "BOTH_FIELD = 'Stemmed and Lemmatized';\n",
    "FIELDS_TO_PROCESS = [DOCUMENT_FIELD, STEMMED_FIELD, LEMMATIZED_FIELD, BOTH_FIELD]\n",
    "\n",
    "\n",
    "VECTORIZERS_2_TRY = {\n",
    "    'CountVectorizer': {\n",
    "        'model': CountVectorizer(lowercase=True),\n",
    "        'params': {\n",
    "            'max_features': [None, 100, 250, 500]\n",
    "        }\n",
    "    },\n",
    "    'TfidfVectorizer': {\n",
    "        'model': TfidfVectorizer(lowercase=True),\n",
    "        'params': {\n",
    "            'max_features': [None, 100, 250, 500]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "# LogisticRegression: For multiclass problems, only ‘newton-cg’, ‘sag’, ‘saga’ and ‘lbfgs’ handle multinomial loss;\n",
    "# ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from\n",
    "# Test L2 separately because we're not going to scale the data\n",
    "REGRESSORS_2_TRY = {\n",
    "    'DecisionTreeClassifier': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'criterion': ['gini','entropy'],\n",
    "            'max_depth': [10, 25, 50, 100, 250, 500]\n",
    "        }\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'n_neighbors': [10, 25, 100, 250, 500],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        }\n",
    "    },\n",
    "    'MultinomialNB': {\n",
    "        'model': MultinomialNB(),\n",
    "        'params': {\n",
    "            'alpha': [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "        }\n",
    "    },\n",
    "    'ComplementNB': {\n",
    "        'model': ComplementNB(),\n",
    "        'params': {\n",
    "            'alpha': [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "        }\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'penalty': ['elasticnet'],\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'solver': ['saga'],\n",
    "            'l1_ratio': np.linspace(0, 1, num=5)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "if DEV_MODE:\n",
    "    RESULT_DIR =  f'{RESULT_DIR}.{EXECUTION_MODE}'\n",
    "    README_FILE = f'./README.{EXECUTION_MODE}.md'\n",
    "    #FIELDS_TO_PROCESS = [DOCUMENT_FIELD, STEMMED_FIELD]\n",
    "    VECTORIZERS_2_TRY['CountVectorizer']['params'] = { 'max_features': [100] }\n",
    "    VECTORIZERS_2_TRY['TfidfVectorizer']['params'] = { 'max_features': [100] }\n",
    "    REGRESSORS_2_TRY['LogisticRegression']['params'] = { 'penalty': ['elasticnet'] , 'C': [0.001, 0.01], 'solver': ['saga'],'l1_ratio': np.linspace(0, 1, num=3)}\n",
    "    REGRESSORS_2_TRY['DecisionTreeClassifier']['params'] = { 'max_depth': [5, 10] }\n",
    "    REGRESSORS_2_TRY['KNeighborsClassifier']['params'] = { 'n_neighbors': [10, 100], 'weights': ['uniform', 'distance']}\n",
    "    REGRESSORS_2_TRY['MultinomialNB']['params'] = { 'alpha': [1, 0.1] }\n",
    "    REGRESSORS_2_TRY['ComplementNB']['params'] = { 'alpha': [1, 0.1] }\n",
    "\n",
    "RESULT_FILE_PREFIX = RESULT_DIR +'/capstone.'\n",
    "IMAGE_PREFIX = RESULT_FILE_PREFIX\n",
    "\n",
    "if not os.path.exists(RESULT_DIR):\n",
    "    os.makedirs(RESULT_DIR)\n",
    "\n",
    "def addMarkdownImage(name, path, asMarkdown=False):\n",
    "    if asMarkdown:\n",
    "        out = f'![{name}]({IMAGE_PREFIX}{path})'\n",
    "    else:\n",
    "        out = f'<a href=\"{IMAGE_PREFIX}{path}\" target=\"_blank\"><img src=\"{IMAGE_PREFIX}{path}\"/></a>'\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "    \n",
    "def writeTargetFieldDistributionDetails(data, targetField, fileNameSuffix, titleSuffix='', width=640, height=480, palette=MAIN_PALETTE_QUALITATIVE):\n",
    "    useFileNameSuffix = fileNameSuffix\n",
    "    if useFileNameSuffix.endswith(\".\"):\n",
    "        useFileNameSuffix = useFileNameSuffix[:-1]\n",
    "\n",
    "    graphsPerRow = 1\n",
    "    widthInches = width * graphsPerRow/100\n",
    "    heightInches = height * 2/100\n",
    "    palette2use = palette\n",
    "    title = f'Data Distribution for {targetField} {titleSuffix}'\n",
    "    \n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(widthInches, heightInches))\n",
    "    #ax = sns.histplot(data=data, y=targetField, palette=palette2use, bins=bins, stat='percent')\n",
    "    #labels = [str(round(v, 2)) if v else '' for v in ax.containers[1].datavalues]\n",
    "    #ax.bar_label(ax.containers[1], labels=labels)\n",
    "    \n",
    "    #fig.suptitle(title)\n",
    "    #fig.tight_layout()\n",
    "    \n",
    "    #create pie chart\n",
    "    targetFieldValueCounts = data[targetField].value_counts()\n",
    "    total = sum(targetFieldValueCounts.values)\n",
    "    def my_fmt(x):\n",
    "        return '{:.2f}% ({:.0f})'.format(x, total*x/100)\n",
    "    colors = sns.color_palette(palette)\n",
    "    patches, labels, pct_texts = plt.pie(targetFieldValueCounts, labels = targetFieldValueCounts.index, colors = colors, autopct=my_fmt, rotatelabels=True)\n",
    "    for label, pct_text in zip(labels, pct_texts):\n",
    "        pct_text.set_rotation(label.get_rotation())\n",
    "    plt.title(title)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(IMAGE_PREFIX + useFileNameSuffix + '.targetField.distribution.png')\n",
    "    #plt.show()\n",
    "\n",
    "        \n",
    "def writeDataFrameDetails(data, fileNameSuffix, writeInfo=False, writeDescribe=False):\n",
    "    buffer = io.StringIO()\n",
    "    data.info(verbose=True, buf=buffer, show_counts=True)\n",
    "    useFileNameSuffix = fileNameSuffix\n",
    "    if useFileNameSuffix.endswith(\".\"):\n",
    "        useFileNameSuffix = useFileNameSuffix[:-1]\n",
    "    if writeInfo:\n",
    "        writeString2File(buffer.getvalue(), RESULT_FILE_PREFIX + useFileNameSuffix + '.data.info.txt')\n",
    "    if writeDescribe:\n",
    "        writeString2File(data.describe(), RESULT_FILE_PREFIX + useFileNameSuffix + '.data.describe.txt')\n",
    "\n",
    "    \n",
    "def printDataFrameInfo(name, stage, showDescribe=True):\n",
    "    out = ''\n",
    "    out += f'### {name}\\n\\n'\n",
    "    out += '<table>'\n",
    "    out += '<tr><th>info()</th>'\n",
    "\n",
    "    if showDescribe:\n",
    "        out += '<th>describe()</th></tr>'\n",
    "\n",
    "    prefix = RESULT_FILE_PREFIX + stage\n",
    "    rawDfInfo = readFile(prefix + '.data.info.txt')\n",
    "    rawDfDescribe = readFile(prefix + '.data.describe.txt')\n",
    "    \n",
    "    out += '<tr>'\n",
    "    out += f'<td><pre>{rawDfInfo}</pre></td>'\n",
    "    if showDescribe:\n",
    "        out += f'<td><pre>{rawDfDescribe}</pre></td>'\n",
    "    out += '</tr>'\n",
    "    out += '</table>\\n\\n'\n",
    "\n",
    "    return out\n",
    "\n",
    "def writeDataFrame2Excel(inputDf, name):\n",
    "    extension = '.dataFrame.xlsx'\n",
    "    if name[-1] == '.':\n",
    "        extension = 'dataFrame.xlsx'\n",
    "    with pd.ExcelWriter(RESULT_FILE_PREFIX + name + extension) as writer:\n",
    "        inputDf.to_excel(writer, index=False)\n",
    "\n",
    "# NOTE: Need this to avoid value truncation in cells\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "def dataFrame2Html(inputDf, path, print2Screen = False):\n",
    "    string2write = inputDf.to_html(index=False)\n",
    "    writeString2File(string2write, IMAGE_PREFIX + path + '.dataFrame.html', print2Screen)\n",
    "\n",
    "def printReadMe(final=False, displayInline=False):\n",
    "    noteBookContent = '## Research Code\\n'\n",
    "    noteBookContent += '**Code:** [Data Analysis Workbook](./capstone.out.ipynb)\\n\\n'\n",
    "    noteBookContent += '**NOTE:** *The processing of the juypter notebook take a long time and often disconnects from the session. In order to run it without monitoring it all the time use the wokraround below from command line.*\\n'\n",
    "    noteBookContent += '```\\n'\n",
    "    noteBookContent += 'jupyter nbconvert --to notebook --execute {input_notebook} --output={output_notebook} --ExecutePreprocessor.timeout=-1\\n'\n",
    "    noteBookContent += '```\\n'\n",
    "    noteBookContent += '<sub>Source: [screen-and-jupyter-a-way-to-run-long-notebooks-headles](https://www.maksimeren.com/post/screen-and-jupyter-a-way-to-run-long-notebooks-headless/)</sub>\\n\\n'\n",
    "    #noteBookContent += 'Jump to the good stuff: [Summary, Observations and Guidance](#next-steps-summary-observations-and-guidance)\\n'\n",
    "    \n",
    "    readMeContent = ''\n",
    "    readMeContent += readFile(RESULT_FILE_PREFIX + 'section01.md', notFoundException=False) + '\\n\\n'\n",
    "    readMeContent += noteBookContent + '\\n\\n'\n",
    "    readMeContent += readFile(RESULT_FILE_PREFIX + 'section02.md', notFoundException=False) + '\\n\\n'\n",
    "    readMeContent += readFile(RESULT_FILE_PREFIX + 'section03.md', notFoundException=False) + '\\n\\n'\n",
    "    readMeContent += readFile(RESULT_FILE_PREFIX + 'section04.md', notFoundException=False) + '\\n\\n'\n",
    "    readMeContent += readFile(RESULT_FILE_PREFIX + 'section05.md', notFoundException=False) + '\\n\\n'\n",
    "    readMeContent += readFile(RESULT_FILE_PREFIX + 'section06.md', notFoundException=False) + '\\n\\n'\n",
    "    readMeContent += readFile(RESULT_FILE_PREFIX + 'section07.md', notFoundException=False) + '\\n\\n'\n",
    "    readMeContent += readFile(RESULT_FILE_PREFIX + 'section08.md', notFoundException=False) + '\\n\\n'\n",
    "    readMeContent += readFile(RESULT_FILE_PREFIX + 'section09.md', notFoundException=False) + '\\n\\n'\n",
    "    readMeContent += readFile(RESULT_FILE_PREFIX + 'section10.md', notFoundException=False) + '\\n\\n'\n",
    "    \n",
    "    # Add metrics only do total on final write\n",
    "    if final:\n",
    "        RUNTIME_METRICS['start_time'] = f'{BEGIN_RUN_DATETIME}'\n",
    "        RUNTIME_METRICS['end_time'] = f'{datetime.datetime.now()}'\n",
    "        RUNTIME_METRICS['total_execution_time'] = timeit.default_timer() - EXECUTION_START_TIME\n",
    "        \n",
    "    jsonRuntimeMetrics = json.dumps(RUNTIME_METRICS, indent=2)\n",
    "    reportingContent = ''\n",
    "    reportingContent += f'# Runtime Metrics:\\n'\n",
    "    reportingContent += '```\\n'\n",
    "    reportingContent += f'{jsonRuntimeMetrics}\\n'\n",
    "    reportingContent += '```\\n'\n",
    "    readMeContent += reportingContent + '\\n\\n'\n",
    "\n",
    "    writeString2File(readMeContent, README_FILE)\n",
    "    if displayInline:\n",
    "        display(Markdown(readMeContent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0a4de-a94a-4d0c-9fda-1c39df199334",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDf = pd.read_csv(INPUT_FILE)\n",
    "rawDf = rawDf.rename(columns={\"Document\": DOCUMENT_FIELD, \"Topic_group\": TARGET_FIELD})\n",
    "rawDf.info()\n",
    "if(DEV_MODE):\n",
    "    SAMPLE_PERCENT = 0.35\n",
    "    rawDf = rawDf.groupby(TARGET_FIELD, group_keys=False).apply(lambda x: x.sample(frac=SAMPLE_PERCENT)) \n",
    "    rawDf.info()\n",
    "\n",
    "writeDataFrameDetails(data=rawDf, fileNameSuffix='raw', writeInfo=True, writeDescribe=True)\n",
    "writeTargetFieldDistributionDetails(data=rawDf, targetField=TARGET_FIELD, fileNameSuffix='raw', titleSuffix='- Raw Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3fdfae-1469-40a8-a46c-8507ffb8b123",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea80e1a-4a06-4d81-9142-f3297cdaf2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionIndex = 1\n",
    "\n",
    "content = '# Capstone: IT Service Ticket Classification\\n'\n",
    "content += '<b color=\"red\">NOTE: All images are clickable and higher resolution images will load in new browser window</b>\\n'\n",
    "content += '## Background\\n'\n",
    "\n",
    "content += 'Most companies have a service desk to help their user or customers with their IT problems.\\n'\n",
    "content += 'Customers log and track their ticket in some digital platform and these get routed to Agents to solve.\\n'\n",
    "content += 'Routing these tickets to the correct person/team to solve is very important:\\n'\n",
    "content += '- A common approach is to \"tag\" the ticket with some classification and there is a mapping that routes based on the tag to the correct team to solve it.\\n'\n",
    "content += '- Tickets incorrectly classified result in them \"bouncing around\" and wasting both agents and customer time.\\n'\n",
    "content += '- There is a financial impact resulting in wasted internal resources and lower customer satisfaction costing the company in real world dollars as well as reputation.\\n'\n",
    "content += '- The scale of the problem grows as you service more users as you need more and more agents to help.\\n'\n",
    "content += '\\n\\n'\n",
    "content += 'This project aims to address this task by finding and building a model to aid in the classification of these tickets into appropriate categories. We will experiment with various types of pre-processing, vectorizers and regression models to help us find the best one to solve for this.\\n\\n'\n",
    "\n",
    "content += '**Dataset**: [IT Service Ticket Classification Dataset](https://www.kaggle.com/datasets/adisongoh/it-service-ticket-classification-dataset)\\n'\n",
    "content += '- This dataset contains 47,837 rows of data and 2 features.\\n\\n'\n",
    "content += 'We will follow the CRISP-DM process model consisting of Business Understanding, Data Understanding, Data Preparation, Modeling, Evaluation, Deployment stages.\\n'\n",
    "sectionStr = str(sectionIndex).zfill(2)\n",
    "writeString2File(content, RESULT_FILE_PREFIX + f'section{sectionStr}.md')\n",
    "printReadMe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee0dbb-2407-4e6d-a735-d4bae766335f",
   "metadata": {},
   "source": [
    "# CRISP-DM: Business Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6356335-8519-4132-9ba6-984d85f4b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionIndex = 2\n",
    "\n",
    "content = '## Business Understanding\\n'\n",
    "content += 'Our goal is to:\\n'\n",
    "content += '- Come up with the best classification model to correctly classify the tickets based solely on the description.\\n'\n",
    "content += '- Provide the business with the best model and hyperparameters to drive the best accuracy.\\n'\n",
    "content += '- Provide the business with alternative models trading accuracy for performance in case that may be a concern or to scale for a much larger dataset that may need re-training.\\n'\n",
    "sectionStr = str(sectionIndex).zfill(2)\n",
    "writeString2File(content, RESULT_FILE_PREFIX + f'section{sectionStr}.md')\n",
    "printReadMe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef94ba48-036f-4fa7-8e52-8c1dec5640ef",
   "metadata": {},
   "source": [
    "# CRISP-DM: Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b863ce-e125-4962-8a9d-ecde17202a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionIndex = 3\n",
    "\n",
    "content = '## Data Understanding\\n'\n",
    "content += '### Data Shape\\n'\n",
    "content += printDataFrameInfo('Raw', 'raw', showDescribe=False)\n",
    "\n",
    "content += '### Features\\n'\n",
    "content += f'- There is only one feature {DOCUMENT_FIELD} which is free form text\\n'\n",
    "content += '- There are no missing values\\n'\n",
    "content += '- All data appears to be in english\\n'\n",
    "content += '- All data appears to be lowercased\\n'\n",
    "content += '- The data set is somewhat large and the classes are imbalanced.\\n'\n",
    "uniqueValues = len(rawDf[TARGET_FIELD].value_counts().values)\n",
    "content += f'- The classification field {TARGET_FIELD} has {uniqueValues} distinct values\\n'\n",
    "imgPath = 'raw.targetField.distribution.png'\n",
    "rawDfStatsImage = addMarkdownImage('Classification Field Data Distribution', f'{imgPath}')\n",
    "content += rawDfStatsImage + '\\n\\n'\n",
    "\n",
    "sectionStr = str(sectionIndex).zfill(2)\n",
    "writeString2File(content, RESULT_FILE_PREFIX + f'section{sectionStr}.md')\n",
    "printReadMe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ceaeb3-67a6-4f0a-8165-5313439bcdb8",
   "metadata": {},
   "source": [
    "# CRISP-DM: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a929ed2-0157-4ba4-b85b-2026b388e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionIndex = 4\n",
    "\n",
    "subMetricNodeName = 'pre_processing';\n",
    "subMetricNode = {}\n",
    "RUNTIME_METRICS[subMetricNodeName] = subMetricNode\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preProcess(row):\n",
    "    text = row[DOCUMENT_FIELD];\n",
    "    textArray = [w for w in word_tokenize(text)]\n",
    "    textCount = len(textArray)\n",
    "    row[DOCUMENT_FIELD + '_count'] = textCount\n",
    "\n",
    "    noStopWordsTextArray = [w for w in textArray if not w.lower() in stop_words]\n",
    "    row[DOCUMENT_FIELD + '_filtered_count'] = len(noStopWordsTextArray)\n",
    "    \n",
    "    \n",
    "    stem = PorterStemmer()\n",
    "    stemArray = [stem.stem(w) for w in noStopWordsTextArray]\n",
    "    stemText =  ' '.join(stemArray)\n",
    "    row[STEMMED_FIELD + '_count'] = len(stemArray)\n",
    "    row[STEMMED_FIELD] = stemText\n",
    "\n",
    "    \n",
    "    lemma = WordNetLemmatizer()\n",
    "    lemmaArray = [lemma.lemmatize(w) for w in noStopWordsTextArray]\n",
    "    lemmaText =  ' '.join(lemmaArray)\n",
    "    row[LEMMATIZED_FIELD + '_count'] = len(stemArray)\n",
    "    row[LEMMATIZED_FIELD] = lemmaText\n",
    "\n",
    "    both = WordNetLemmatizer()\n",
    "    bothArray = [both.lemmatize(w) for w in word_tokenize(stemText)]\n",
    "    bothText =  ' '.join(bothArray)\n",
    "    row[BOTH_FIELD + '_count'] = len(bothArray)\n",
    "    row[BOTH_FIELD] = bothText \n",
    "    \n",
    "    return row\n",
    "\n",
    "experimentDf = rawDf.copy()\n",
    "\n",
    "startTime = timeit.default_timer()\n",
    "experimentDf = experimentDf.apply(preProcess, axis=1)\n",
    "#display(experimentDf.head())\n",
    "subMetricNode['total_time'] = timeit.default_timer() - startTime\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure(figsize=(12, 4.8))\n",
    "countFields = [DOCUMENT_FIELD + '_count', DOCUMENT_FIELD + '_filtered_count', STEMMED_FIELD + '_count', LEMMATIZED_FIELD + '_count', BOTH_FIELD + '_count', TARGET_FIELD]\n",
    "\n",
    "ax = sns.histplot(data=experimentDf[countFields], palette='pastel', kde=True)\n",
    "ax.set_title('Token Count Distribution')\n",
    "# ax.set_ylabel('Model + Vectorizer')\n",
    "ax.set_xlabel('# Tokens')\n",
    "# for i in ax.containers:\n",
    "#     ax.bar_label(i,label_type='edge')\n",
    "# sns.move_legend(ax, legendLocation, bbox_to_anchor=bboxAnchor)\n",
    "fig.tight_layout()\n",
    "plt.savefig(IMAGE_PREFIX + 'pre_process.token_count_distribution.png')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "content = '## Data Preparation\\n'\n",
    "content += '### Pre-Processing Decisions\\n'\n",
    "content += '- We will need to:\\n'\n",
    "content += '  - lowercase the data\\n'\n",
    "content += '  - remove stop words\\n'\n",
    "content += '  - stem, lemmatize or combination of both\\n'\n",
    "content += '- We will create three columns for variations of stem, lemmatize, stem+lemmatize and then run through models to evaluate which is best\\n'\n",
    "content += \"  - I am opting to do this here because while normally we would bake this into the Pipeline since we are experimenting I want to optmize the process and just process these once instead of each time we switch the model during cross validation stage.\"\n",
    "content += addMarkdownImage('Token Distribution', 'pre_process.token_count_distribution.png') + '\\n\\n'\n",
    "content += '### Analysis\\n'\n",
    "content += \"- It is interesting to note both looking at the data and the distribution plot of tokens which doesn't appear to shift much after pre-processing that the data has been through some level of pre-processing already.\\n\"\n",
    "content += \"- Once pre-processing is done a majority of the tokens fall below 200 we can use this to set the upper bound for some of the model hyperparameters.\\n\"\n",
    "\n",
    "sectionStr = str(sectionIndex).zfill(2)\n",
    "writeString2File(content, RESULT_FILE_PREFIX + f'section{sectionStr}.md')\n",
    "printReadMe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14700cc-0592-44e2-ba46-80207d2caba6",
   "metadata": {},
   "source": [
    "# CRISP-DM: Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396064be-42a5-4d94-9dab-f10b87732893",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionIndex = 5\n",
    "\n",
    "subMetricNodeName = 'modeling';\n",
    "subMetricNode = {}\n",
    "RUNTIME_METRICS[subMetricNodeName] = subMetricNode\n",
    "startTime = timeit.default_timer()\n",
    "\n",
    "#display(experimentDf.head())\n",
    "X = experimentDf[FIELDS_TO_PROCESS]\n",
    "y = experimentDf[TARGET_FIELD]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "yTrainDf = pd.DataFrame({TARGET_FIELD: y_train.values})\n",
    "yTestDf = pd.DataFrame({TARGET_FIELD: y_test.values})\n",
    "display(yTestDf)\n",
    "writeTargetFieldDistributionDetails(data=yTrainDf, targetField=TARGET_FIELD, fileNameSuffix='model_results.y_train', titleSuffix='- Train')\n",
    "writeTargetFieldDistributionDetails(data=yTestDf, targetField=TARGET_FIELD, fileNameSuffix='model_results.y_test', titleSuffix='- Test')\n",
    "\n",
    "#point at reportDf for now so we can update for long run\n",
    "def dumpIntermediateReport(reportDf):\n",
    "    # Dump results after each run so easier to track progress over long run\n",
    "    writeDataFrame2Excel(reportDf, 'model_results')\n",
    "    #print(reportDf)\n",
    "    subMetricNode['total_time'] = timeit.default_timer() - startTime\n",
    "    \n",
    "    content = '## Modeling\\n'\n",
    "    content += '### Feature Engineering Decisions\\n'\n",
    "    content += '- No real feature engineering is needed as we have no missing data and nothing to impute. The preprocessing takes care of most of the needs for stemming and lemmatization before our modeling stage.\\n'\n",
    "    content += '- When creating intial train and test sets (30% of data for testing) we will stratify the set so that both train and test sets contain similar percentages of the classes because they are imbalanced.\\n'\n",
    "    content += '- When we do our grid search split because the target classes are imbalanced we will use StratifiedKFold so the splits are representative of the orginal set and class balances.\\n'\n",
    "    content += '- We will try the following models:\\n'\n",
    "    content += '  - LogisticRegression: We will use elasticnet since it intergates l1 and l2 penalties rather than having to pick between ridge and lasso.\\n'\n",
    "    content += '  - Decision Tree: While not expecting the best performance a decision tree could help us in explainability of how a decision is made and derive important \"features/tokens\"\\n'\n",
    "    content += '  - Naive Bayes: We will use Multinomail and Complement. Complement is meant to deal better with imbalanced classes but we shall see.\\n'\n",
    "    content += '  - KNN: Will use k nearest neigbhours, one would expect that tickets in the same category would have similar words and so would cluster well together\\n'\n",
    "    \n",
    "    content += '\\n'\n",
    "    content += '### Data Distribution\\n'\n",
    "    content += 'Checking to make sure our test and train datasets represent the class imbalances\\n'\n",
    "    content += '<table>\\n'\n",
    "    content += '<tr>\\n'\n",
    "    content += '<td>\\n'\n",
    "    content += addMarkdownImage('Class Distribution - Train', 'model_results.y_train.targetField.distribution.png')\n",
    "    content += '</td>\\n'\n",
    "    content += '<td>\\n'\n",
    "    content += addMarkdownImage('Class Distribution - Train', 'model_results.y_test.targetField.distribution.png')\n",
    "    content += '</td>\\n'\n",
    "    content += '</tr>\\n'\n",
    "    content += '</table>\\n\\n'\n",
    "    \n",
    "    dataDf = pd.read_excel(RESULT_FILE_PREFIX + 'model_results.dataFrame.xlsx')\n",
    "    \n",
    "    copyDf = dataDf.copy()\n",
    "    dataDf['pipeline'] = dataDf.apply(lambda row: (row['model'] + ' ' + row['vectorizer']), axis=1)\n",
    "    \n",
    "    #display(dataDf.head())\n",
    "    \n",
    "    legendLocation='lower left'\n",
    "    bboxAnchor=(1, 0.5)\n",
    "    \n",
    "    dataDf = dataDf.sort_values('best_score', ascending=False)\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    ax = sns.barplot(data=dataDf, y='pipeline', x='best_score', hue='input_field', palette='pastel')\n",
    "    ax.set_title('Model + Vectorizer vs Accuracy')\n",
    "    ax.set_ylabel('Model + Vectorizer')\n",
    "    ax.set_xlabel('Accuracy')\n",
    "    for i in ax.containers:\n",
    "        ax.bar_label(i,label_type='center')\n",
    "    sns.move_legend(ax, legendLocation, bbox_to_anchor=bboxAnchor)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(IMAGE_PREFIX + 'model_results.accuracy.png')\n",
    "    #plt.show()\n",
    "    \n",
    "    dataDf = dataDf.sort_values('mean_fit_time', ascending=True)\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    ax = sns.barplot(data=dataDf, y='pipeline', x='mean_fit_time', hue='input_field', palette='pastel')\n",
    "    ax.set_ylabel('Model + Vectorizer')\n",
    "    ax.set_xlabel('Mean Fit Time')\n",
    "    for i in ax.containers:\n",
    "        ax.bar_label(i,label_type='center')\n",
    "    sns.move_legend(ax, legendLocation, bbox_to_anchor=bboxAnchor)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(IMAGE_PREFIX + 'model_results.fit_time.png')\n",
    "    #plt.show()\n",
    "    \n",
    "    content += '### Model Results\\n'\n",
    "    headers = {\n",
    "        'selector': 'th',\n",
    "        'props': 'font-size: 8pt; font-family: Verdana;'\n",
    "    }\n",
    "    \n",
    "    html = (\n",
    "        copyDf.style\n",
    "        .set_properties(**{'font-size': '8pt', 'font-family': 'Verdana'})\n",
    "        .set_table_styles([headers])\n",
    "        .hide(axis=\"index\")\n",
    "        .highlight_max(axis=0, subset=['best_score'], props='font-weight:bold; background-color:#CCE0AC;')\n",
    "        .highlight_min(axis=0, subset=['best_score'], props='font-weight:bold; background-color:#FF8A8A;')\n",
    "        .highlight_min(axis=0, subset=['mean_fit_time'], props='font-weight:bold; background-color:#CCE0AC;')\n",
    "        .highlight_max(axis=0, subset=['mean_fit_time'], props='font-weight:bold; background-color:#FF8A8A;')\n",
    "        .render()\n",
    "    )\n",
    "    #content += copyDf.to_html(index=False) + '\\n\\n'\n",
    "    content += html + '\\n\\n'\n",
    "    \n",
    "    content += '### Analysis\\n'\n",
    "    content += '<table>\\n'\n",
    "    content += '<tr>\\n'\n",
    "    content += '<th>Accuracy</th>\\n'\n",
    "    content += '<th>Fit Time</th>\\n'\n",
    "    content += '</tr>\\n'\n",
    "    \n",
    "    content += '<tr>\\n'\n",
    "    content += '<td>' + addMarkdownImage('Model Accuracy', 'model_results.accuracy.png') + '</td>\\n'\n",
    "    content += '<td>' + addMarkdownImage('Model Fit Time', 'model_results.fit_time.png') + '</td>\\n'\n",
    "    content += '</tr>\\n'\n",
    "    \n",
    "    \n",
    "    def printPerf(prefix, data, sortField, ascending=False):\n",
    "        data = data.sort_values(sortField, ascending=ascending)\n",
    "        checkFieldValue = data.iloc[0][sortField]\n",
    "    \n",
    "        nodes = data.loc[data[sortField] == checkFieldValue]\n",
    "        out = ''\n",
    "        if nodes.shape[0] == 1:\n",
    "            for i, row in nodes.iterrows():\n",
    "                currModel = row['model']\n",
    "                currVectorizer = row['vectorizer']\n",
    "                currScore = row['best_score'] * 100\n",
    "                currParams = row['best_params']\n",
    "                currFitTime = row['mean_fit_time']\n",
    "                currInputField = row['input_field']\n",
    "                out += f'{prefix} {currModel} with vectorizer {currVectorizer} with input pre-processing {currInputField} had accuracy score {currScore}% and mean fit time of {currFitTime} seconds.'\n",
    "        else :\n",
    "            out += f'{prefix}\\n<ul>\\n'\n",
    "            for i, row in nodes.iterrows():\n",
    "                currModel = row['model']\n",
    "                currVectorizer = row['vectorizer']\n",
    "                currScore = row['best_score'] * 100\n",
    "                currParams = row['best_params']\n",
    "                currFitTime = row['mean_fit_time']\n",
    "                currInputField = row['input_field']\n",
    "                out += f'<li> {currModel} with vectorizer {currVectorizer} with input pre-processing {currInputField} had accuracy score {currScore}% and mean fit time of {currFitTime} seconds.</li>'\n",
    "            out += '</ul>\\n'\n",
    "        return out;\n",
    "        \n",
    "    content += '<tr>\\n'\n",
    "    content += '<td><ul>\\n'\n",
    "    content += '<li>' + printPerf('The best model was:\\n', copyDf, 'best_score', False) + '</li>'\n",
    "    content += '<li>' + printPerf('The worst model was:\\n', copyDf, 'best_score', True) + '</li>'\n",
    "    content += '</ul></td>\\n'\n",
    "    content += '<td><ul>\\n'\n",
    "    content += '<li>' + printPerf('The fastest model was:\\n', copyDf, 'mean_fit_time', True) + '</li>'\n",
    "    content += '<li>' + printPerf('The slowest model was\\n', copyDf, 'mean_fit_time', False) + '</li>'\n",
    "    content += '</ul></td>\\n'\n",
    "    content += '</tr>\\n'\n",
    "    \n",
    "    content += '</table>\\n\\n'\n",
    "    \n",
    "    sectionStr = str(sectionIndex).zfill(2)\n",
    "    writeString2File(content, RESULT_FILE_PREFIX + f'section{sectionStr}.md')\n",
    "    printReadMe()\n",
    "\n",
    "#print(y_train.value_counts(normalize=True))\n",
    "#print(y_test.value_counts(normalize=True))\n",
    "reportDf = pd.DataFrame(columns=['model', 'vectorizer', 'input_field', 'best_score', 'mean_fit_time', 'best_params', 'run_time'])\n",
    "for mk in REGRESSORS_2_TRY:\n",
    "    model = REGRESSORS_2_TRY[mk]\n",
    "    modelParams = model['params']\n",
    "    modelUsed = f'{mk}'\n",
    "    modelMetricNode = {}\n",
    "    modelStartTime = timeit.default_timer()\n",
    "    subMetricNode[mk] = modelMetricNode\n",
    "    for vk in VECTORIZERS_2_TRY:\n",
    "        vectorizer = VECTORIZERS_2_TRY[vk]\n",
    "        vectorizerUsed = f'{vk}'\n",
    "        vectorizerParams = vectorizer['params']\n",
    "        vectorMetricNode = {}\n",
    "        vectorizerStartTime = timeit.default_timer()\n",
    "        modelMetricNode[vk] = vectorMetricNode\n",
    "        pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer['model']),\n",
    "            ('model', model['model'])\n",
    "        ])\n",
    "        finalParams = {}\n",
    "        for k in vectorizerParams:\n",
    "            finalParams['vectorizer__' + k] = vectorizerParams[k]\n",
    "\n",
    "        for k in modelParams:\n",
    "            finalParams['model__' + k] = modelParams[k]\n",
    "\n",
    "        for f in FIELDS_TO_PROCESS:\n",
    "            fieldMetricNode = {}\n",
    "            vectorMetricNode[f] = fieldMetricNode\n",
    "            experimentStartTime = timeit.default_timer()\n",
    "            #cv = StratifiedKFold(n_splits=5, shuffle=True) # Not needed as per documentation\n",
    "            # For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, \n",
    "            # StratifiedKFold is used. In all other cases, KFold is used. These splitters are instantiated with \n",
    "            # shuffle=False so the splits will be the same across calls.\n",
    "            grid = GridSearchCV(pipeline, param_grid=finalParams, n_jobs=GRID_SEARCH_JOBS)\n",
    "            inputDf = X_train[f]\n",
    "            testDf = X_test[f]\n",
    "            grid.fit(inputDf, y_train)\n",
    "            #print(grid.cv_results_)\n",
    "            bestAccuracyScore = grid.score(testDf, y_test)\n",
    "            bestParams = json.dumps(grid.best_params_)\n",
    "            meanFitTime = np.mean(grid.cv_results_['mean_fit_time'])\n",
    "            runTime = timeit.default_timer() - experimentStartTime\n",
    "            fieldMetricNode['total_time'] = runTime\n",
    "            reportDf.loc[reportDf.shape[0]] = [modelUsed, vectorizerUsed, f, bestAccuracyScore, meanFitTime, bestParams, runTime]\n",
    "\n",
    "            dumpIntermediateReport(reportDf)\n",
    "        vectorMetricNode['total_time'] =  timeit.default_timer() - vectorizerStartTime\n",
    "    modelMetricNode = timeit.default_timer() - modelStartTime\n",
    "\n",
    "# Read back in the final report\n",
    "dataDf = pd.read_excel(RESULT_FILE_PREFIX + 'model_results.dataFrame.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe262275-d1c7-4514-8378-84a1ccde371b",
   "metadata": {},
   "source": [
    "# CRISP-DM: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9595df-de41-4a0b-a8b5-3dec22aac36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionIndex = 6\n",
    "\n",
    "dataDf = pd.read_excel(RESULT_FILE_PREFIX + 'model_results.dataFrame.xlsx')\n",
    "# Now take the best model and calculate the confusion matrix\n",
    "dataDf = dataDf.sort_values('best_score', ascending=False)\n",
    "bestScore = dataDf.iloc[0]['best_score']\n",
    "bestModel = dataDf.iloc[0]['model']\n",
    "bestVectorizer = dataDf.iloc[0]['vectorizer']\n",
    "bestParams = dataDf.iloc[0]['best_params']\n",
    "bestInputField = dataDf.iloc[0]['input_field']\n",
    "\n",
    "model = REGRESSORS_2_TRY[bestModel]\n",
    "vectorizer = VECTORIZERS_2_TRY[bestVectorizer]\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer['model']),\n",
    "    ('model', model['model'])\n",
    "])\n",
    "\n",
    "finalParams = json.loads(bestParams)\n",
    "for x in finalParams:\n",
    "    value = finalParams[x]\n",
    "    finalParams[x] = [value]\n",
    "\n",
    "X = experimentDf[FIELDS_TO_PROCESS]\n",
    "y = experimentDf[TARGET_FIELD]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "grid = GridSearchCV(pipeline, param_grid=finalParams, n_jobs=GRID_SEARCH_JOBS)\n",
    "grid.fit(X_train[bestInputField], y_train)\n",
    "y_pred_train_final = grid.best_estimator_.predict(X_train[bestInputField])\n",
    "y_pred_test_final = grid.best_estimator_.predict(X_test[bestInputField])\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(1, 1, squeeze=False)\n",
    "fig.set_size_inches(6.4, 6.4)\n",
    "ax[0,0].set_title('Confusion Matrix - Train')\n",
    "ConfusionMatrixDisplay.from_estimator(grid.best_estimator_, X_train[bestInputField], y_train, xticks_rotation='vertical', colorbar=False, cmap='Blues', ax=ax[0,0])\n",
    "fig.tight_layout()\n",
    "plt.savefig(IMAGE_PREFIX + 'evaluation.confusion_matrix.train.png')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(1, 1, squeeze=False)\n",
    "fig.set_size_inches(6.4, 6.4)\n",
    "ConfusionMatrixDisplay.from_estimator(grid.best_estimator_, X_test[bestInputField], y_test, xticks_rotation='vertical', colorbar=False, cmap='Greens', ax=ax[0,0])\n",
    "ax[0,0].set_title('Confusion Matrix - Test')\n",
    "fig.tight_layout()\n",
    "plt.savefig(IMAGE_PREFIX + 'evaluation.confusion_matrix.test.png')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "content = '## Evaluation\\n'\n",
    "content += f'We will now run our best pipeline which had an accuracy score of {bestScore * 100:.2f}%:\\n'\n",
    "content += f'- Preprocessing={bestInputField}\\n'\n",
    "content += f'- Vectorizer={bestVectorizer}\\n'\n",
    "content += f'- Model={bestModel} ({bestParams})\\n\\n'\n",
    "\n",
    "content += '### Results\\n'\n",
    "content += '<table>\\n'\n",
    "content += '<tr>\\n'\n",
    "content += f'<th></th>\\n'\n",
    "content += f'<th>Train</th>\\n'\n",
    "content += f'<th>Test</th>\\n'\n",
    "content += '</tr>\\n'\n",
    "content += '<tr>\\n'\n",
    "content += f'<td>Classification Report</td>\\n'\n",
    "content += '<td>\\n\\n'\n",
    "content += '```\\n\\n'\n",
    "content += classification_report(y_train, y_pred_train_final) + '\\n'\n",
    "content += '```\\n\\n'\n",
    "content += '</td>\\n'\n",
    "content += '<td>\\n\\n'\n",
    "content += '```\\n\\n'\n",
    "content += classification_report(y_test, y_pred_test_final) + '\\n'\n",
    "content += '```\\n\\n'\n",
    "content += '</td>\\n'\n",
    "content += '</tr>\\n'\n",
    "content += '<tr>\\n'\n",
    "content += f'<td>Confusion Matrix</td>\\n'\n",
    "content += '<td>\\n\\n'\n",
    "content += addMarkdownImage('Confusion Matrix - Train', 'evaluation.confusion_matrix.train.png') \n",
    "content += '</td>\\n'\n",
    "content += '<td>\\n\\n'\n",
    "content += addMarkdownImage('Confusion Matrix - Test', 'evaluation.confusion_matrix.test.png') \n",
    "content += '</td>\\n'\n",
    "content += '</tr>\\n'\n",
    "content += '</table>\\n\\n'\n",
    "\n",
    "sectionStr = str(sectionIndex).zfill(2)\n",
    "writeString2File(content, RESULT_FILE_PREFIX + f'section{sectionStr}.md')\n",
    "printReadMe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa73eddb-32c7-4243-8b3a-83cd3ac0ced2",
   "metadata": {},
   "source": [
    "# CRISP-DM: Deployment, Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfdb8af-6821-4e48-aeb5-cbacb921dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectionIndex = 7\n",
    "content = '## Deployment and Future Work\\n'\n",
    "content += '### Observations\\n'\n",
    "content += '- We got lucky with this dataset and the data seemed to have some level of preprocessing (unclear based on documentation) done for us but lowercasing and removing stop words is a must.\\n'\n",
    "content += f'- {bestInputField} field performed best for accuracy. Surprisngly stemming and lemmatization had worse performance. More analysis may be needed, however the loss in accuracy is not significant enough. We would still prefer to do lemmatization which gives next best accuracy.\\n'\n",
    "content += f'- The {bestVectorizer} paired with various models performs best. We should definitely use {bestVectorizer} in our pipeline.\\n'\n",
    "content += '- It is very clear that while Logistic Regression performed best the processing time is very high.\\n'\n",
    "content += '### Model/Pipeline Selection\\n'\n",
    "content += f'- Given the choice if we want to maximize accuracy we would pick our best pipeline which had an accuracy score of {bestScore * 100:.2f}%:\\n'\n",
    "content += f'  - Preprocessing={bestInputField}\\n'\n",
    "content += f'  - Vectorizer={bestVectorizer}\\n'\n",
    "content += f'  - Model={bestModel} ({bestParams})\\n\\n'\n",
    "content += f'- In general if we want a model capable of dealing with larger sets where training time is a concern and we can trade off on accuracy I would go with:\\n'\n",
    "content += f'  - Complement Naive Bayes as industry expectation is the data will be imbalanced for IT tickets. Even though it was third best the kNN classifier was only marginally better\\n'\n",
    "content += '### Next Steps\\n'\n",
    "content += 'Deep learning may be able get us even better results. This would be worth researching.\\n\\n'\n",
    "\n",
    "sectionStr = str(sectionIndex).zfill(2)\n",
    "writeString2File(content, RESULT_FILE_PREFIX + f'section{sectionStr}.md')\n",
    "printReadMe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee3eec-fa82-47ad-b69e-4278d595a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do final printout\n",
    "printReadMe(final=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee3962-06a3-4d01-a8db-65c9a6b8eab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
